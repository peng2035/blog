<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[98:Validate Binary Search Tree]]></title>
    <url>%2F2018%2F04%2F18%2F98-Validate-Binary-Search-Tree%2F</url>
    <content type="text"><![CDATA[Given a binary tree, determine if it is a valid binary search tree (BST). Assume a BST is defined as follows: The left subtree of a node contains only nodes with keys less than the node’s key. The right subtree of a node contains only nodes with keys greater than the node’s key. Both the left and right subtrees must also be binary search trees. Example 1: 2 / \ 1 3 Binary tree [2,1,3] , return true. Example 2: 1 / \ 2 3 Binary tree [1,2,3] , return false. 1234567891011public class Solution &#123; public boolean isValidBST(TreeNode root) &#123; return isValidBST(root, Integer.MIN_VALUE, Integer.MAX_VALUE); &#125; public boolean isValidBST(TreeNode root, int minVal, int maxVal) &#123; if (root == null) return true; if (root.val &gt;= maxVal || root.val &lt;= minVal) return false; return isValidBST(root.left, minVal, root.val) &amp;&amp; isValidBST(root.right, root.val, maxVal); &#125;&#125; 曾经的做法有点蠢12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Solution &#123; public boolean isValidBST(TreeNode node) &#123; if(node==null) &#123; return true; &#125; if(node.left!=null) &#123; if(node.left.val &gt;= node.val || node.val &lt;= getMaxValue(node.left)) &#123; return false; &#125; else &#123; if(isValidBST(node.left) == false) &#123; return false; &#125; &#125; &#125; if(node.right!=null) &#123; if(node.right.val &lt;= node.val || node.val &gt;= getMinValue(node.right)) &#123; return false; &#125; else &#123; if(isValidBST(node.right) == false) &#123; return false; &#125; &#125; &#125; return true; &#125; private int getMaxValue(TreeNode node) &#123; while(node.right != null) &#123; node = node.right; &#125; return node.val; &#125; private int getMinValue(TreeNode node) &#123; while(node.left != null) &#123; node = node.left; &#125; return node.val; &#125;&#125;]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池]]></title>
    <url>%2F2018%2F04%2F17%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[参数 int corePoolSize：核心线程数 int maximumPoolSize：最大线程数 BlockingQueue workQueue：任务队列 long keepAliveTime：和TimeUnit unit一起构成线程的最大空闲时间，一旦超过该时间还没有任务处理，该线程就走向结束了。它是针对当前线程数已经超过corePoolSize核心线程数了或者核心线程数也开启超时策略，即属性allowCoreThreadTimeOut=true ThreadFactory threadFactory：线程工厂 RejectedExecutionHandler handler：拒绝策略，当任务太多来不及处理，可拒绝该任务 先简单描述下ThreadPoolExecutor的execute(futureTask)过程的大概情况： 如果当前线程数小于corePoolSize，则直接创建出一个线程，用于执行新加进来的任务 如果当前线程数已经超过corePoolSize，则将该任务放到BlockingQueue workQueue任务队列中，该任务队列可以是有限容量也可以是无限容量的。每个线程处理完一个任务后，都会不断的从BlockingQueue workQueue任务队列中取出任务并执行 如果BlockingQueue workQueue是有限容量的，已满无法放进新的任务了，如果此时的线程数小于maximumPoolSize，则直接创建一个线程执行该任务 如果线程数已达到maximumPoolSize不能再创建线程了，则直接使用RejectedExecutionHandler handler拒绝该任务 execute1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * Executes the given task sometime in the future. The task * may execute in a new thread or in an existing pooled thread. * * If the task cannot be submitted for execution, either because this * executor has been shutdown or because its capacity has been reached, * the task is handled by the current &#123;@code RejectedExecutionHandler&#125;. * * @param command the task to execute * @throws RejectedExecutionException at discretion of * &#123;@code RejectedExecutionHandler&#125;, if the task * cannot be accepted for execution * @throws NullPointerException if &#123;@code command&#125; is null */public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn't, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; // 小于核心线程池，无脑加线程 // new worker 是当前线程池里的人物 if (addWorker(command, true)) return; c = ctl.get(); &#125; // 核心线程不会销毁，那么此时一定是&gt;core pool size 的状态 // offer方法在无界队列的时候不能返回false // 在有界队列的时候会返回false if (isRunning(c) &amp;&amp; workQueue.offer(command)) // recheck的目的是判断是否要新加一个线程 // 但是 判断isRunning 的状态是为什么呢（感觉不加也不会出事） // todo // 在下面那个else if(isRunning(recheck) &amp;&amp; ...)会不会有问题 int recheck = ctl.get(); // 假设有个线程在此时被释放了（可能core pool size == 0，又或者调用了shutdown方法） // 考虑recheck 和 c的差别 // 如果不check的话，isRunning的状态也不会改变应该，Running状态是通过高3位的状态来判断 // 期间就差了一个判断（几乎不耗时）和一个immediately返回的offer操作且get与if之间依旧可能被其他线程插入 // 感觉只有性能上的差别 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 可能的情况 // 1.core pool size == 0 的情况下，比如new CachedThreadPool() // 在超过keepAliveTime的时候可能会有worker == 0 的情况发生 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // workQ 是个有界队列的情况下，无视core pool size 强行扩展到max pool size else if (!addWorker(command, false)) reject(command);&#125; addWorker123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122/** * Checks if a new worker can be added with respect to current * pool state and the given bound (either core or maximum). If so, * the worker count is adjusted accordingly, and, if possible, a * new worker is created and started, running firstTask as its * first task. This method returns false if the pool is stopped or * eligible to shut down. It also returns false if the thread * factory fails to create a thread when asked. If the thread * creation fails, either due to the thread factory returning * null, or due to an exception (typically OutOfMemoryError in * Thread.start()), we roll back cleanly. * * @param firstTask the task the new thread should run first (or * null if none). Workers are created with an initial first task * (in method execute()) to bypass queuing when there are fewer * than corePoolSize threads (in which case we always start one), * or when the queue is full (in which case we must bypass queue). * Initially idle threads are usually created via * prestartCoreThread or to replace other dying workers. * * @param core if true use corePoolSize as bound, else * maximumPoolSize. (A boolean indicator is used here rather than a * value to ensure reads of fresh values after checking other pool * state). * @return true if successful */private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. // 在rs == shutdown 的时候，任意firstTask != null &amp;&amp; workQ不为空都不会返回false // 换句话说就是有执行的任务，即使是shutdown状态依旧会有addWaiter流程 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); // core 表明是否是核心线程 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl // cas 失败的情况下判断 线程池状态 // 如果状态没变 则 无脑cas // 状态有变就要去外层判断了 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; // if t == null 可能表示的是ThreadFactory出问题了 if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); // 当shutdown &amp;&amp; firstTask != null 要回滚 // todo 什么情况下会是shut down &amp;&amp; first task == null if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 所有对worker的操作都需要加锁 workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125;/** * Rolls back the worker thread creation. * - removes worker from workers, if present * - decrements worker count * - rechecks for termination, in case the existence of this * worker was holding up termination */private void addWorkerFailed(Worker w) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (w != null) workers.remove(w); decrementWorkerCount(); tryTerminate(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; worker123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175/** * Main worker run loop. Repeatedly gets tasks from queue and * executes them, while coping with a number of issues: * * 1. We may start out with an initial task, in which case we * don't need to get the first one. Otherwise, as long as pool is * running, we get tasks from getTask. If it returns null then the * worker exits due to changed pool state or configuration * parameters. Other exits result from exception throws in * external code, in which case completedAbruptly holds, which * usually leads processWorkerExit to replace this thread. * * 2. Before running any task, the lock is acquired to prevent * other pool interrupts while the task is executing, and then we * ensure that unless pool is stopping, this thread does not have * its interrupt set. * * 3. Each task run is preceded by a call to beforeExecute, which * might throw an exception, in which case we cause thread to die * (breaking loop with completedAbruptly true) without processing * the task. * * 4. Assuming beforeExecute completes normally, we run the task, * gathering any of its thrown exceptions to send to afterExecute. * We separately handle RuntimeException, Error (both of which the * specs guarantee that we trap) and arbitrary Throwables. * Because we cannot rethrow Throwables within Runnable.run, we * wrap them within Errors on the way out (to the thread's * UncaughtExceptionHandler). Any thrown exception also * conservatively causes thread to die. * * 5. After task.run completes, we call afterExecute, which may * also throw an exception, which will also cause thread to * die. According to JLS Sec 14.20, this exception is the one that * will be in effect even if task.run throws. * * The net effect of the exception mechanics is that afterExecute * and the thread's UncaughtExceptionHandler have as accurate * information as we can provide about any problems encountered by * user code. * * @param w the worker */final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; // 在getTask的时候会释放worker计数 // 此时getTask方法返回null while (task != null || (task = getTask()) != null) &#123; // worker继承自AQS， tryAcquire不可以充入，可重入就没有意义了 w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; // 完成对worker的释放 processWorkerExit(w, completedAbruptly); &#125;&#125;/** * Performs cleanup and bookkeeping for a dying worker. Called * only from worker threads. Unless completedAbruptly is set, * assumes that workerCount has already been adjusted to account * for exit. This method removes thread from worker set, and * possibly terminates the pool or replaces the worker if either * it exited due to user task exception or if fewer than * corePoolSize workers are running or queue is non-empty but * there are no workers. * * @param w the worker * @param completedAbruptly if the worker died due to user exception */private void processWorkerExit(Worker w, boolean completedAbruptly) // 外层发生异常没有执行到最后才为true if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; completedTaskCount += w.completedTasks; workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; // 在workQ有任务的时候至少保证有一个worker int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; addWorker(null, false); &#125;&#125;/** * Transitions to TERMINATED state if either (SHUTDOWN and pool * and queue empty) or (STOP and pool empty). If otherwise * eligible to terminate but workerCount is nonzero, interrupts an * idle worker to ensure that shutdown signals propagate. This * method must be called following any action that might make * termination possible -- reducing worker count or removing tasks * from the queue during shutdown. The method is non-private to * allow access from ScheduledThreadPoolExecutor. */final void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; // if (workerCountOf(c) != 0) &#123; // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; &#125; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; terminated(); &#125; finally &#123; ctl.set(ctlOf(TERMINATED, 0)); termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // else retry on failed CAS &#125;&#125; getTask123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * Performs blocking or timed wait for a task, depending on * current configuration settings, or returns null if this worker * must exit because of any of: * 1. There are more than maximumPoolSize workers (due to * a call to setMaximumPoolSize). * 2. The pool is stopped. * 3. The pool is shutdown and the queue is empty. * 4. This worker timed out waiting for a task, and timed-out * workers are subject to termination (that is, * &#123;@code allowCoreThreadTimeOut || workerCount &gt; corePoolSize&#125;) * both before and after the timed wait, and if the queue is * non-empty, this worker is not the last thread in the pool. * * @return task, or null if the worker must exit, in which case * workerCount is decremented */private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; // cas 释放所有的worker（仅仅改变一下ctl） decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // Are workers subject to culling? // 判断worker是否能被回收 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; // 第一次循环 timedOut无脑false, poll方法拿不到之后为true // 当workQueue isEmpty 的时候删除所有线程 // 否则至少保留一个核心线程来执行 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; // poll 方法拿不到task timedOut = true Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125;]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>复习</tag>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Condition]]></title>
    <url>%2F2018%2F04%2F16%2FCondition%2F</url>
    <content type="text"><![CDATA[使用获取锁后对应sync的wait &amp; notify（notifyAll） await123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143// await 方法是获取了锁的状态下，所以不需要进行大量的cas操作public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 添加condition内部链表的节点 Node node = addConditionWaiter(); // 解放掉在sync queue中的节点 int savedState = fullyRelease(node); int interruptMode = 0; // 判断当前的线程是否在Sync队列中,判断节点是不是在同步队列中， // 因为上一步已经释放了锁，也就是说此时可能有线程已经获取锁同时可能已经调用了singal方法， // 如果已经唤醒，那么就不应该park了，而是退出while方法，从而继续争抢锁 while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; // acquire方法中的判断能否执行，并设置头结点等等 // 此为condition在await处被唤醒后 // 此处被唤醒的时候，节点已经处于sync q之中了 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125;/** * Adds a new waiter to wait queue. * @return its new wait node */private Node addConditionWaiter() &#123; Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; //Node(Thread thread, int waitStatus) &#123; // Used by Condition // this.waitStatus = waitStatus; // this.thread = thread; //&#125; Node node = new Node(Thread.currentThread(), Node.CONDITION); // 清除所有多余节点后，t==null 意味着头结点为空 if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node;&#125;/** * Unlinks cancelled waiter nodes from condition queue. * Called only while holding lock. This is called when * cancellation occurred during condition wait, and upon * insertion of a new waiter when lastWaiter is seen to have * been cancelled. This method is needed to avoid garbage * retention in the absence of signals. So even though it may * require a full traversal, it comes into play only when * timeouts or cancellations occur in the absence of * signals. It traverses all nodes rather than stopping at a * particular target to unlink all pointers to garbage nodes * without requiring many re-traversals during cancellation * storms. */ // 移除当前节点 ，如果节点的waitStatus != Node.condition // 因为节点只有向后指正，所以只能遍历 // Called only while holding lock. 关键private void unlinkCancelledWaiters() &#123; Node t = firstWaiter; // 前驱节点 Node trail = null; while (t != null) &#123; Node next = t.nextWaiter; // 分头中尾三种情况移除当前节点 if (t.waitStatus != Node.CONDITION) &#123; t.nextWaiter = null; // 说明是头结点 if (trail == null) firstWaiter = next; else trail.nextWaiter = next; if (next == null) lastWaiter = trail; &#125; else trail = t; t = next; &#125;&#125;/** * Invokes release with current state value; returns saved state. * Cancels node and throws exception on failure. * @param node the condition node for this wait * @return previous sync state */final int fullyRelease(Node node) &#123; boolean failed = true; try &#123; // 当前线程锁了多少个status（重入了N次） int savedState = getState(); // 从sync q中移除，调用的就是unlock的release方法 if (release(savedState)) &#123; failed = false; return savedState; &#125; else &#123; throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; if (failed) // 一些错误的操作,导致节点被取消 node.waitStatus = Node.CANCELLED; &#125;&#125;/** * Returns true if a node, always one that was initially placed on * a condition queue, is now waiting to reacquire on sync queue. * @param node the node * @return true if is reacquiring */final boolean isOnSyncQueue(Node node) &#123; // node.waitStatus == CONDITION 的时候说明还不子啊sync q中 if (node.waitStatus == Node.CONDITION || node.prev == null) return false; // 在add waiter 中的代码，t.nextWaiter = node，只有在sync q中会设置next，而condition中不会 if (node.next != null) // If has successor, it must be on queue return true; /* * node.prev can be non-null, but not yet on queue because * the CAS to place it on queue can fail. So we have to * traverse from tail to make sure it actually made it. It * will always be near the tail in calls to this method, and * unless the CAS failed (which is unlikely), it will be * there, so we hardly ever traverse much. */ return findNodeFromTail(node);&#125; signal123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * Moves the longest-waiting thread, if one exists, from the * wait queue for this condition to the wait queue for the * owning lock. * * @throws IllegalMonitorStateException if &#123;@link #isHeldExclusively&#125; * returns &#123;@code false&#125; */public final void signal() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) // 唤醒头结点（condition的） doSignal(first);&#125;/** * Removes and transfers nodes until hit non-cancelled one or * null. Split out from signal in part to encourage compilers * to inline the case of no waiters. * @param first (non-null) the first node on condition queue */private void doSignal(Node first) &#123; do &#123; if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; // 遍历整个队列，唤醒一个可以唤醒的node // 而signal则只有first != null的判断 &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null);&#125;/** * Transfers a node from a condition queue onto sync queue. * Returns true if successful. * @param node the node * @return true if successfully transferred (else the node was * cancelled before signal) */final boolean transferForSignal(Node node) &#123; /* * If cannot change waitStatus, the node has been cancelled. */ if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; /* * Splice onto queue and try to set waitStatus of predecessor to * indicate that thread is (probably) waiting. If cancelled or * attempt to set waitStatus fails, wake up to resync (in which * case the waitStatus can be transiently and harmlessly wrong). */ Node p = enq(node); int ws = p.waitStatus; // 正常情况下 unpark是不会在这里执行的 // 和sync一样，notify不是实时生效，而是等sync退出后，通过unlock来唤醒后续节点 if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;&#125;]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>cocurrent</tag>
        <tag>java</tag>
        <tag>复习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读写锁]]></title>
    <url>%2F2018%2F04%2F12%2F%E8%AF%BB%E5%86%99%E9%94%81%2F</url>
    <content type="text"><![CDATA[ReentrantReadWriteLock 定义ReentrantReadWriteLock: Reentrant(重入) Read (读) Write(写) Lock(锁), 从字面意思我们了解到, 这是一个可重入的读写锁;ReentrantReadWriteLock 主要具有以下特点 读 写锁都可重入, 线程可同时具有读 写锁 线程同时获取读写锁时, 必须先获取 writeLock, 再获取 readLock (也就是锁的降级), 反过来的直接导致死锁(这个问题下面会重点分析) ReentrantReadWriteLock支持公平与非公平机制, 主要依据是 AQS 类中的Sync Queue 里面是否有节点 或 Sync Queue 里面的 head.next 是否是获取 writeLock 的线程节点; 公平模式就会依据获取的先后顺序在 SyncQueue 里面排队获取读写锁互斥 获取 readLock 的过程中, 若 此时有线程已获取写锁 或 AQS 的 Sync Queue 里面有 获取 writeLock 的线程, 则一定会等待获取writeLock成功并释放或放弃获取 后才能获取(PS: 这里有个例外, 在死锁时, 已获取 readLock 的线程还是能重复获取 readLock) 获取 writeLock 时 一定是在没有线程获取 readLock 或 writeLock 时才获取成功 (PS: 一个典型的死锁场景就是 一个线程先获取readLock, 后又获取writeLock) 锁的获取支持线程中断, 且writeLock 中支持 Condition (PS: condition 只支持排他的场景) 参数123456789101112131415161718192021static final int SHARED_SHIFT = 16;static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT);static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1;static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;// 高16位读锁，低16位写锁（总量）/** Returns the number of shared holds represented in count */static int sharedCount(int c) &#123; return c &gt;&gt;&gt; SHARED_SHIFT; &#125;/** Returns the number of exclusive holds represented in count */static int exclusiveCount(int c) &#123; return c &amp; EXCLUSIVE_MASK; &#125;/** * A counter for per-thread read hold counts. * Maintained as a ThreadLocal; cached in cachedHoldCounter */ //线程所拥有的锁static final class HoldCounter &#123; int count = 0; // Use id, not reference, to avoid garbage retention final long tid = getThreadId(Thread.currentThread());&#125; 读锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191final boolean tryReadLock() &#123; Thread current = Thread.currentThread(); for (;;) &#123; int c = getState(); // 同线程既可以获得读锁也可以获得写锁 // 有独占锁且不是获得独占锁线程的将不能获得写锁 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return false; int r = sharedCount(c); if (r == MAX_COUNT) throw new Error("Maximum lock count exceeded"); // 单次在高16位增加1，所以在上层做一个MAX_COUNT == 的操作就足够了。不用改成&gt;= if (compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; // 缓存上一个获得锁的线程（减少threadLocal.get的操作） HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return true; &#125; &#125;&#125;protected final int tryAcquireShared(int unused) &#123; /* * Walkthrough: * 1. If write lock held by another thread, fail. * 2. Otherwise, this thread is eligible for * lock wrt state, so ask if it should block * because of queue policy. If not, try * to grant by CASing state and updating count. * Note that step does not check for reentrant * acquires, which is postponed to full version * to avoid having to check hold count in * the more typical non-reentrant case. * 3. If step 2 fails either because thread * apparently not eligible or CAS fails or count * saturated, chain to version with full retry loop. */ Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c); // 公正锁情况下只要有前驱节点就要block // 而非公正锁的情况下，只有头结点是独占锁的情况下才会阻塞（代码详见下面） // 其他步骤和上述tryReadLock一样 if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125;/** * Nonfair version of Sync */static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = -8159625535654395037L; final boolean writerShouldBlock() &#123; return false; // writers can always barge &#125; final boolean readerShouldBlock() &#123; /* As a heuristic to avoid indefinite writer starvation, * block if the thread that momentarily appears to be head * of queue, if one exists, is a waiting writer. This is * only a probabilistic effect since a new reader will not * block if there is a waiting writer behind other enabled * readers that have not yet drained from the queue. */ return apparentlyFirstQueuedIsExclusive(); &#125;&#125;/** * Returns &#123;@code true&#125; if the apparent first queued thread, if one * exists, is waiting in exclusive mode. If this method returns * &#123;@code true&#125;, and the current thread is attempting to acquire in * shared mode (that is, this method is invoked from &#123;@link * #tryAcquireShared&#125;) then it is guaranteed that the current thread * is not the first queued thread. Used only as a heuristic in * ReentrantReadWriteLock. */final boolean apparentlyFirstQueuedIsExclusive() &#123; Node h, s; return (h = head) != null &amp;&amp; (s = h.next) != null &amp;&amp; !s.isShared() &amp;&amp; s.thread != null;&#125;/** * Fair version of Sync */static final class FairSync extends Sync &#123; private static final long serialVersionUID = -2274990926593161451L; final boolean writerShouldBlock() &#123; return hasQueuedPredecessors(); &#125; final boolean readerShouldBlock() &#123; return hasQueuedPredecessors(); &#125;&#125;/*** Full version of acquire for reads, that handles CAS misses* and reentrant reads not dealt with in tryAcquireShared.*/final int fullTryAcquireShared(Thread current) &#123; /* * This code is in part redundant with that in * tryAcquireShared but is simpler overall by not * complicating tryAcquireShared with interactions between * retries and lazily reading hold counts. */ HoldCounter rh = null; for (;;) &#123; int c = getState(); if (exclusiveCount(c) != 0) &#123; if (getExclusiveOwnerThread() != current) return -1; // else we hold the exclusive lock; blocking here // would cause deadlock. // 应该被block的情况 // 此时获取独占锁的且已经是当前线程的（可能锁已经被解放的了） &#125; else if (readerShouldBlock()) &#123; // Make sure we're not acquiring read lock reentrantly if (firstReader == current) &#123; // assert firstReaderHoldCount &gt; 0; &#125; else &#123; // threadLocal 变量需要remove 否则可能会造成内存泄露 if (rh == null) &#123; rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) &#123; rh = readHolds.get(); if (rh.count == 0) // 惰性删除 readHolds.remove(); &#125; &#125; if (rh.count == 0) return -1; &#125; &#125; if (sharedCount(c) == MAX_COUNT) throw new Error("Maximum lock count exceeded"); if (compareAndSetState(c, c + SHARED_UNIT)) &#123; if (sharedCount(c) == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; if (rh == null) rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; cachedHoldCounter = rh; // cache for release &#125; return 1; &#125; &#125;&#125; 写锁12345678910111213141516171819202122232425262728293031323334protected final boolean tryAcquire(int acquires) &#123; /* * Walkthrough: * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c); if (c != 0) &#123; // 其他的线程已经获取读锁 // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error("Maximum lock count exceeded"); // Reentrant acquire setState(c + acquires); return true; &#125; // c==0 // 非公正锁下 writerShouldBlock 无脑return false if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true;&#125; 参考ReentrantReadWriteLock 源码分析参考读锁为什么不能升级成写锁]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AQS(简要)]]></title>
    <url>%2F2018%2F04%2F11%2FAQS(%E7%AE%80%E8%A6%81)%2F</url>
    <content type="text"><![CDATA[独占锁acquire123456789101112131415161718192021/** * Acquires in exclusive mode, ignoring interrupts. Implemented * by invoking at least once &#123;@link #tryAcquire&#125;, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking &#123;@link * #tryAcquire&#125; until success. This method can be used * to implement method &#123;@link Lock#lock&#125;. * * @param arg the acquire argument. This value is conveyed to * &#123;@link #tryAcquire&#125; but is otherwise uninterpreted and * can represent anything you like. */public final void acquire(int arg) &#123; // tryAcquire用于确认是否能够获取到锁（根据status的状态来判定），默认需要继承类自己来实现 // Node.EXCLUSIVE 独占锁标志 // addWaiter是将该节点加入到后续节点之中 // acquireQueued是将当前线程阻塞（其实LockSupport.park()是线程waiting，而不是blocking） if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 是否可重入取决于tryAquire的实现，包括公正锁非公正锁实现等等 addWaiter123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124/** * Creates and enqueues node for current thread and given mode. * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */ // 当前方法只是塞节点（并不涉及任何阻塞操作）private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 如果已经被初始化过head &amp; tail，可以先cas一下 // 大多数情况下没有那么强的竞争，一次就可以解决所有问题 // enq有部分初始化的功能，加上死循环的cas Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125;/** * Inserts node into queue, initializing if necessary. See picture above. * @param node the node to insert * @return node's predecessor */private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize // 初始化流程，包含cas判断，防止创建多个head // 空节点时，head == tail 等于new node() if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; // 曾经一度认为链表的两段式操作一定要加锁 // 其实只要cas node tail成功就可以 // 就算不成功，当前node.prev重新设置就可以了，不影响原链表 // 只需要操作tail节点，因为head节点是当前操作的线程 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125;/** * Acquires in exclusive uninterruptible mode for thread already in * queue. Used by condition wait methods as well as acquire. * * @param node the node * @param arg the acquire argument * @return &#123;@code true&#125; if interrupted while waiting */final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); // 在park之前先判断一下是否能够被唤醒 // unpark之后判断是否是执行线程 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // parkAndCheckInterrupt 即是调用 LockSupport方法 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; //当时不明白为什么要这个finally操作，当时可以理解的部分是可能出现了runtimeException //翻看了1.6的代码，确实是catch(RuntimeException e) &#123;cancel&#125; if (failed) cancelAcquire(node); &#125;&#125;/** * Checks and updates status for a node that failed to acquire. * Returns true if thread should block. This is the main signal * control in all acquire loops. Requires that pred == node.prev. * * @param pred node's predecessor holding status * @param node the node * @return &#123;@code true&#125; if thread should block */private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ // cancelled 所以需要直接跳过 do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; ReentrantLock中tryAcquire的实现（公正锁）12345678910111213141516171819202122232425262728293031/** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; //公正锁非公正锁区别取决于hasQueuedPredecessors这个方法 //hasQueuedPredecessors用于判断当前队列是否有后续的排队节点 //state == 0 表示当前没有其他的竞争线程 //1.头结点线程已经执行完了，后续的节点还没有被唤醒 //2.在q中没有任何节点，也就是锁没有线程在竞争的状态 //公正锁就是保证了在情况1下面，后续节点在与外部节点竞争的情况下能够公正的排到q的tail上去，而不是在state==0的时候就直接执行 //每一步操作都不是原子操作，所以需要cas（status）来做最后的保证 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; // 可重入锁的操作 int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; 123456789101112131415// 进入该方法的时候可能已经有其他线程唤醒了头部，或者有新的头结点介入了public final boolean hasQueuedPredecessors() &#123; // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. // volatile 用内存屏障保证了多个volatile变量写不会重排序 // todo (Read fields in reverse initialization order) 最后一行应该不论正反读都是能保证可见性的 Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; // 在初始化的时候 head先初始化，tail = head // 可能存在的情况是head初始化完毕且tail没有初始化完成，所以需要判断h.next == null来判断操作是否在进行中 // 如果有并发操作在进行节点操作说明可能有多余的节点生成 return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());&#125; 解锁1234567891011121314151617181920/** * Releases in exclusive mode. Implemented by unblocking one or * more threads if &#123;@link #tryRelease&#125; returns true. * This method can be used to implement method &#123;@link Lock#unlock&#125;. * * @param arg the release argument. This value is conveyed to * &#123;@link #tryRelease&#125; but is otherwise uninterpreted and * can represent anything you like. * @return the value returned from &#123;@link #tryRelease&#125; */public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; // h == null 则不需要unpark if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; unparkSuccessor12345678910111213141516171819202122232425262728293031323334353637/** * Wakes up node's successor, if one exists. * * @param node the node */private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 从尾部而不是从头开始是因为prev是可靠地 // 因为只有在prev之后才会进行cas来塞tail，如果tail塞成功证明prev一定是有效的 // 然而因为next是在cas之后，所以是不可靠的。 // 而效率问题 // 因为仅仅在s==null的情况下，或者s.waitStatus &gt; 0 的情况下，大概率来说，在上述两行之间不会存在插入过多节点的效率问题 // 可能的情况是，下一个节点被cancel，而后面堆积了很多节点，此时效率可能会很低？（待验证） for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; ReentrantLock tryRelease 实现1234567891011121314protected final boolean tryRelease(int releases) &#123; // 独占锁的解锁相对简单，单线程不需要cas int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 判断可重入锁的情况 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 共享锁acquireShared1234567891011121314151617/** * Acquires in shared mode, ignoring interrupts. Implemented by * first invoking at least once &#123;@link #tryAcquireShared&#125;, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking &#123;@link * #tryAcquireShared&#125; until success. * * @param arg the acquire argument. This value is conveyed to * &#123;@link #tryAcquireShared&#125; but is otherwise uninterpreted * and can represent anything you like. */public final void acquireShared(int arg) &#123; // tryAcquireShared &gt; 0 表示后续节点可以获取锁 // = 0 表示后续节点不能获取到锁 if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; doAcquireSharedInterruptibly123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117/** * Acquires in shared interruptible mode. * @param arg the acquire argument */private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); // 确保了当前节点node p的前驱节点 if (p == head) &#123; // 和独占锁的主要差别在这个方法 // 因为status保证了可见性，所以此处一定能保证执行setHeadAndProagate的头结点一定需要被唤醒 int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;/** * Sets head of queue, and checks if successor may be waiting * in shared mode, if so propagating if either propagate &gt; 0 or * PROPAGATE status was set. * * @param node the node * @param propagate the return value from a tryAcquireShared */private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); // 这之后可能引起外层head的失控 // 两个线程同时执行unpark方法（共享锁） // 线程1在塞完head之后被停止，给到线程2，线程2透过外层的p == head的校验 // 可以进入到setHead方法，此时head不再是线程1设置的head，而是thread2设置的head // 此时在执行到h == head 的时候，线程1和线程2的h均为线程2的node // 然后当前线程就接着执行下去 // 所以此时是不强保证head的原子操作的 // todo 再想想 /* * Try to signal next queued node if: * Propagation was indicated by caller, * or was recorded (as h.waitStatus either before * or after setHead) by a previous operation * (note: this uses sign-check of waitStatus because * PROPAGATE status may transition to SIGNAL.) * and * The next node is waiting in shared mode, * or we don't know, because it appears null * * The conservatism in both of these checks may cause * unnecessary wake-ups, but only when there are multiple * racing acquires/releases, so most need signals now or soon * anyway. */ // 当propagate == 0 时，后续节点将不再能够获得锁。 // 如果propagate &gt; 0, 则说明后续节点能够再次获得锁 // h == null || h.waitStatus &lt; 0 均表示没有需要执行的节点 // h = head 保证了当前节点 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) // 共享锁会在唤醒当前节点的时候同时唤醒后续节点 doReleaseShared(); &#125;&#125;/** * Release action for shared mode -- signals successor and ensures * propagation. (Note: For exclusive mode, release just amounts * to calling unparkSuccessor of head if it needs signal.) */private void doReleaseShared() &#123; /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; // 在park那个方法中会把后续节点设置为Signal if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; // todo 不懂什么时候会执行 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; Semaphore中tryAcquire（fair）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Attempts to acquire in shared mode. This method should query if * the state of the object permits it to be acquired in the shared * mode, and if so to acquire it. * * &lt;p&gt;This method is always invoked by the thread performing * acquire. If this method reports failure, the acquire method * may queue the thread, if it is not already queued, until it is * signalled by a release from some other thread. * * &lt;p&gt;The default implementation throws &#123;@link * UnsupportedOperationException&#125;. * * @param arg the acquire argument. This value is always the one * passed to an acquire method, or is the value saved on entry * to a condition wait. The value is otherwise uninterpreted * and can represent anything you like. * @return a negative value on failure; zero if acquisition in shared * mode succeeded but no subsequent shared-mode acquire can * succeed; and a positive value if acquisition in shared * mode succeeded and subsequent shared-mode acquires might * also succeed, in which case a subsequent waiting thread * must check availability. (Support for three different * return values enables this method to be used in contexts * where acquires only sometimes act exclusively.) Upon * success, this object has been acquired. * @throws IllegalMonitorStateException if acquiring would place this * synchronizer in an illegal state. This exception must be * thrown in a consistent fashion for synchronization to work * correctly. * @throws UnsupportedOperationException if shared mode is not supported */ //上述是tryAcquireShared的说明protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; //与独占锁一样，用于判断是否有后续节点 if (hasQueuedPredecessors()) return -1; //Semaphore中 status初始化=permits //通过status的值来判断通量有多少 int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125; 解锁12345678910111213141516/** * Releases in shared mode. Implemented by unblocking one or more * threads if &#123;@link #tryReleaseShared&#125; returns true. * * @param arg the release argument. This value is conveyed to * &#123;@link #tryReleaseShared&#125; but is otherwise uninterpreted * and can represent anything you like. * @return the value returned from &#123;@link #tryReleaseShared&#125; */public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; Semaphore tryReleaseShared12345678910protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int current = getState(); int next = current + releases; if (next &lt; current) // overflow throw new Error("Maximum permit count exceeded"); if (compareAndSetState(current, next)) return true; &#125;&#125;]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>concurrent</tag>
        <tag>aqs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis复制]]></title>
    <url>%2F2018%2F04%2F10%2Fredis%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[slaveof 命令如果是通过配置文件配置的主从，主会广播，但是通过slaveof 命令返回ok的主从，只有第一次复制数据（todo 为什么） 全量复制 主服务器调用bgsave，生成rdb文件 生成rdb文件的同时，将增量的命令写入缓冲区暂存 rdb同步给从服务器 缓冲区命令发送给从服务器 达到一致的状态 缺点bgsave的成本很高，如果仅仅是短时间断线，全量的数据同步有点不靠谱 增量复制 主服务器和从服务器同时维护一个偏移量，偏移量大小为同步的字节数 当主从一致的时候，偏移量大小是一致的 偏移量不一致的时候，主服务器会维护一个定长队列来存储最近一部分的命令，带有偏移量标识，用于同步 如果需要同步的值超过了队列的大小，那么就要启用全量同步了 之前有个问题一直没有想明白。由于所有的命令不一定都是幂等操作，命令+偏移量也不一定是一个原子操作，那么是先修改偏移量还是先执行命令，好像都有问题 现在想明白了，增量复制仅适用于网络波动，而不适用于机器挂了的情况。如果机器挂了，偏移量也没了，毕竟不落地，全量很安全。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis键过期]]></title>
    <url>%2F2018%2F04%2F10%2Fredis%E9%94%AE%E8%BF%87%E6%9C%9F%2F</url>
    <content type="text"><![CDATA[过期数据结构 expires 指向一个dict， dict内部存放每个键的过期时间。 过期键删除策略定时删除每次 expire的时候创建一个定时器，通过定时器来删除 优点 键会尽可能快速的被回收，节省内存 缺点 对cpu非常不友好，对性能要求较高的缓存服务器来说不可接受惰性删除等到使用时采取检查是否过期 优点 对cpu友好，不会花费额外的时间去处理过期键 缺点 对内存不友好，如果不被访问永远不会删除 定期删除每过一段时间就对数据做一次删除，控制删除的量。中和策略。但是不能准确的过期。 redis过期策略惰性删除和定期删除 定时删除是由一个timer来执行12345678void aeMain(aeEventLoop *eventLoop) &#123; eventLoop-&gt;stop = 0; while (!eventLoop-&gt;stop) &#123; if (eventLoop-&gt;beforesleep != NULL) eventLoop-&gt;beforesleep(eventLoop); aeProcessEvents(eventLoop, AE_ALL_EVENTS); &#125;&#125; aof &amp; rdb 复制功能对过期键的处理 从服务器一律不处理，主一律处理 从服务器不处理惰性过期，等待主服务器的过期信息(expiredIfNeeded 中的源代码)12345678/* If we are running in the context of a slave, return ASAP: * the slave key expiration is controlled by the master that will * send us synthesized DEL operations for expired keys. * * Still we try to return the right information to the caller, * that is, 0 if we think the key should be still valid, 1 if * we think the key is expired at this time. */if (server.masterhost != NULL) return now &gt; when;]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis持久化机制]]></title>
    <url>%2F2018%2F04%2F10%2Fredis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[rdb持久化成一个二进制的快照文件，可以用于还原redis的数据。但是在不同版本的redis中不兼容，在之前用unstable版本的redis启动过一次，再用3.2启动会报rdb的version有问题。 save源代码同进程创建rdb文件。server端阻塞。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144/* Save the DB on disk. Return C_ERR on error, C_OK on success. */int rdbSave(char *filename) &#123; char tmpfile[256]; char cwd[MAXPATHLEN]; /* Current working dir path for error messages. */ FILE *fp; rio rdb; int error = 0; // 创建文件 snprintf(tmpfile,256,"temp-%d.rdb", (int) getpid()); fp = fopen(tmpfile,"w"); if (!fp) &#123; char *cwdp = getcwd(cwd,MAXPATHLEN); serverLog(LL_WARNING, "Failed opening the RDB file %s (in server root dir %s) " "for saving: %s", filename, cwdp ? cwdp : "unknown", strerror(errno)); return C_ERR; &#125; // 初始化io rioInitWithFile(&amp;rdb,fp); //真正存储的逻辑 if (rdbSaveRio(&amp;rdb,&amp;error) == C_ERR) &#123; errno = error; goto werr; &#125; /* Make sure data will not remain on the OS's output buffers */ if (fflush(fp) == EOF) goto werr; if (fsync(fileno(fp)) == -1) goto werr; if (fclose(fp) == EOF) goto werr; /* Use RENAME to make sure the DB file is changed atomically only * if the generate DB file is ok. */ if (rename(tmpfile,filename) == -1) &#123; char *cwdp = getcwd(cwd,MAXPATHLEN); serverLog(LL_WARNING, "Error moving temp DB file %s on the final " "destination %s (in server root dir %s): %s", tmpfile, filename, cwdp ? cwdp : "unknown", strerror(errno)); unlink(tmpfile); return C_ERR; &#125; serverLog(LL_NOTICE,"DB saved on disk"); server.dirty = 0; server.lastsave = time(NULL); server.lastbgsave_status = C_OK; return C_OK;werr: serverLog(LL_WARNING,"Write error saving DB on disk: %s", strerror(errno)); fclose(fp); unlink(tmpfile); return C_ERR;&#125;/* Produces a dump of the database in RDB format sending it to the specified * Redis I/O channel. On success C_OK is returned, otherwise C_ERR * is returned and part of the output, or all the output, can be * missing because of I/O errors. * * When the function returns C_ERR and if 'error' is not NULL, the * integer pointed by 'error' is set to the value of errno just after the I/O * error. */int rdbSaveRio(rio *rdb, int *error) &#123; dictIterator *di = NULL; dictEntry *de; char magic[10]; int j; long long now = mstime(); uint64_t cksum; if (server.rdb_checksum) rdb-&gt;update_cksum = rioGenericUpdateChecksum; // 给当前的rdb加上版本号 snprintf(magic,sizeof(magic),"REDIS%04d",RDB_VERSION); if (rdbWriteRaw(rdb,magic,9) == -1) goto werr; if (rdbSaveInfoAuxFields(rdb) == -1) goto werr; // 遍历整个redis的db for (j = 0; j &lt; server.dbnum; j++) &#123; redisDb *db = server.db+j; dict *d = db-&gt;dict; if (dictSize(d) == 0) continue; di = dictGetSafeIterator(d); if (!di) return C_ERR; /* Write the SELECT DB opcode */ if (rdbSaveType(rdb,RDB_OPCODE_SELECTDB) == -1) goto werr; if (rdbSaveLen(rdb,j) == -1) goto werr; /* Write the RESIZE DB opcode. We trim the size to UINT32_MAX, which * is currently the largest type we are able to represent in RDB sizes. * However this does not limit the actual size of the DB to load since * these sizes are just hints to resize the hash tables. */ uint32_t db_size, expires_size; db_size = (dictSize(db-&gt;dict) &lt;= UINT32_MAX) ? dictSize(db-&gt;dict) : UINT32_MAX; expires_size = (dictSize(db-&gt;expires) &lt;= UINT32_MAX) ? dictSize(db-&gt;expires) : UINT32_MAX; if (rdbSaveType(rdb,RDB_OPCODE_RESIZEDB) == -1) goto werr; if (rdbSaveLen(rdb,db_size) == -1) goto werr; if (rdbSaveLen(rdb,expires_size) == -1) goto werr; /* Iterate this DB writing every entry */ while((de = dictNext(di)) != NULL) &#123; sds keystr = dictGetKey(de); robj key, *o = dictGetVal(de); long long expire; initStaticStringObject(key,keystr); expire = getExpire(db,&amp;key); if (rdbSaveKeyValuePair(rdb,&amp;key,o,expire,now) == -1) goto werr; &#125; dictReleaseIterator(di); &#125; di = NULL; /* So that we don't release it again on error. */ /* EOF opcode */ if (rdbSaveType(rdb,RDB_OPCODE_EOF) == -1) goto werr; /* CRC64 checksum. It will be zero if checksum computation is disabled, the * loading code skips the check in this case. */ cksum = rdb-&gt;cksum; memrev64ifbe(&amp;cksum); if (rioWrite(rdb,&amp;cksum,8) == 0) goto werr; return C_OK;werr: if (error) *error = errno; if (di) dictReleaseIterator(di); return C_ERR;&#125; 创建一个文件做校验，然后轮训每个数据库对数据进行二进制编码以及落盘。 bgsave源代码创建一个子进程来创建rdb文件。server端不阻塞。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748int rdbSaveBackground(char *filename) &#123; pid_t childpid; long long start; if (server.aof_child_pid != -1 || server.rdb_child_pid != -1) return C_ERR; server.dirty_before_bgsave = server.dirty; server.lastbgsave_try = time(NULL); start = ustime(); if ((childpid = fork()) == 0) &#123; int retval; /* Child */ closeListeningSockets(0); redisSetProcTitle("redis-rdb-bgsave"); retval = rdbSave(filename); if (retval == C_OK) &#123; size_t private_dirty = zmalloc_get_private_dirty(); if (private_dirty) &#123; serverLog(LL_NOTICE, "RDB: %zu MB of memory used by copy-on-write", private_dirty/(1024*1024)); &#125; &#125; exitFromChild((retval == C_OK) ? 0 : 1); &#125; else &#123; /* Parent */ // fork 的时间肯能会持续很久，bgsave fork 是阻塞的 server.stat_fork_time = ustime()-start; server.stat_fork_rate = (double) zmalloc_used_memory() * 1000000 / server.stat_fork_time / (1024*1024*1024); /* GB per second. */ latencyAddSampleIfNeeded("fork",server.stat_fork_time/1000); if (childpid == -1) &#123; server.lastbgsave_status = C_ERR; serverLog(LL_WARNING,"Can't save in background: fork: %s", strerror(errno)); return C_ERR; &#125; serverLog(LL_NOTICE,"Background saving started by pid %d",childpid); server.rdb_save_time_start = time(NULL); server.rdb_child_pid = childpid; server.rdb_child_type = RDB_CHILD_TYPE_DISK; updateDictResizePolicy(); return C_OK; &#125; return C_OK; /* unreached */&#125; 核心代码就是fork了一个子进程。但是如果是复制代码块内存需要两份，但是不复制代码的话是怎么保证快照呢。 在Linux程序中，fork（）会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，出于效率考虑，linux中引入了“写时复制“技术，也就是只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程。 写时拷贝（copy on write） 增量技术。 关于(fork)[https://www.cnblogs.com/biyeymyhjob/archive/2012/07/20/2601655.html] AOF(append only file)通过保存Redis服务器所执行的写命令来记录数据库状态的。 ![AOF]实时调用栈 源代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879void feedAppendOnlyFile(struct redisCommand *cmd, int dictid, robj **argv, int argc) &#123; sds buf = sdsempty(); robj *tmpargv[3]; /* The DB this command was targeting is not the same as the last command * we appendend. To issue a SELECT command is needed. * * 使用 SELECT 命令，显式设置数据库，确保之后的命令被设置到正确的数据库 */ if (dictid != server.aof_selected_db) &#123; char seldb[64]; snprintf(seldb,sizeof(seldb),"%d",dictid); buf = sdscatprintf(buf,"*2\r\n$6\r\nSELECT\r\n$%lu\r\n%s\r\n", (unsigned long)strlen(seldb),seldb); server.aof_selected_db = dictid; &#125; // EXPIRE 、 PEXPIRE 和 EXPIREAT 命令 if (cmd-&gt;proc == expireCommand || cmd-&gt;proc == pexpireCommand || cmd-&gt;proc == expireatCommand) &#123; /* Translate EXPIRE/PEXPIRE/EXPIREAT into PEXPIREAT * * 将 EXPIRE 、 PEXPIRE 和 EXPIREAT 都翻译成 PEXPIREAT */ buf = catAppendOnlyExpireAtCommand(buf,cmd,argv[1],argv[2]); // SETEX 和 PSETEX 命令 &#125; else if (cmd-&gt;proc == setexCommand || cmd-&gt;proc == psetexCommand) &#123; /* Translate SETEX/PSETEX to SET and PEXPIREAT * * 将两个命令都翻译成 SET 和 PEXPIREAT */ // SET tmpargv[0] = createStringObject("SET",3); tmpargv[1] = argv[1]; tmpargv[2] = argv[3]; buf = catAppendOnlyGenericCommand(buf,3,tmpargv); // PEXPIREAT decrRefCount(tmpargv[0]); buf = catAppendOnlyExpireAtCommand(buf,cmd,argv[1],argv[2]); // 其他命令 &#125; else &#123; /* All the other commands don't need translation or need the * same translation already operated in the command vector * for the replication itself. */ buf = catAppendOnlyGenericCommand(buf,argc,argv); &#125; /* Append to the AOF buffer. This will be flushed on disk just before * of re-entering the event loop, so before the client will get a * positive reply about the operation performed. * * 将命令追加到 AOF 缓存中， * 在重新进入事件循环之前，这些命令会被冲洗到磁盘上， * 并向客户端返回一个回复。 */ if (server.aof_state == REDIS_AOF_ON) server.aof_buf = sdscatlen(server.aof_buf,buf,sdslen(buf)); /* If a background append only file rewriting is in progress we want to * accumulate the differences between the child DB and the current one * in a buffer, so that when the child process will do its work we * can append the differences to the new append only file. * * 如果 BGREWRITEAOF 正在进行， * 那么我们还需要将命令追加到重写缓存中， * 从而记录当前正在重写的 AOF 文件和数据库当前状态的差异。 */ if (server.aof_child_pid != -1) aofRewriteBufferAppend((unsigned char*)buf,sdslen(buf)); // 释放 sdsfree(buf);&#125; server.aof_buf：aof缓冲，由于aof不是实时刷盘，记录只能先记录到内存中的一个sds中写入需要等eventloops调用时间事件去运行flush方法才真正的写入文件之中 aof重写aof文件是记录命令，对同一个key的行为会记录多次，会造成空间的浪费，重写有助于减少空间。 源代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169/* Write a sequence of commands able to fully rebuild the dataset into * "filename". Used both by REWRITEAOF and BGREWRITEAOF. * * 将一集足以还原当前数据集的命令写入到 filename 指定的文件中。 * * 这个函数被 REWRITEAOF 和 BGREWRITEAOF 两个命令调用。 * （REWRITEAOF 似乎已经是一个废弃的命令） * * In order to minimize the number of commands needed in the rewritten * log Redis uses variadic commands when possible, such as RPUSH, SADD * and ZADD. However at max REDIS_AOF_REWRITE_ITEMS_PER_CMD items per time * are inserted using a single command. * * 为了最小化重建数据集所需执行的命令数量， * Redis 会尽可能地使用接受可变参数数量的命令，比如 RPUSH 、SADD 和 ZADD 等。 * * 不过单个命令每次处理的元素数量不能超过 REDIS_AOF_REWRITE_ITEMS_PER_CMD 。 */int rewriteAppendOnlyFile(char *filename) &#123; dictIterator *di = NULL; dictEntry *de; rio aof; FILE *fp; char tmpfile[256]; int j; long long now = mstime(); /* Note that we have to use a different temp name here compared to the * one used by rewriteAppendOnlyFileBackground() function. * * 创建临时文件 * * 注意这里创建的文件名和 rewriteAppendOnlyFileBackground() 创建的文件名稍有不同 */ snprintf(tmpfile,256,"temp-rewriteaof-%d.aof", (int) getpid()); fp = fopen(tmpfile,"w"); if (!fp) &#123; redisLog(REDIS_WARNING, "Opening the temp file for AOF rewrite in rewriteAppendOnlyFile(): %s", strerror(errno)); return REDIS_ERR; &#125; // 初始化文件 io rioInitWithFile(&amp;aof,fp); // 设置每写入 REDIS_AOF_AUTOSYNC_BYTES 字节 // 就执行一次 FSYNC // 防止缓存中积累太多命令内容，造成 I/O 阻塞时间过长 if (server.aof_rewrite_incremental_fsync) rioSetAutoSync(&amp;aof,REDIS_AOF_AUTOSYNC_BYTES); // 遍历所有数据库 for (j = 0; j &lt; server.dbnum; j++) &#123; char selectcmd[] = "*2\r\n$6\r\nSELECT\r\n"; redisDb *db = server.db+j; // 指向键空间 dict *d = db-&gt;dict; if (dictSize(d) == 0) continue; // 创建键空间迭代器 di = dictGetSafeIterator(d); if (!di) &#123; fclose(fp); return REDIS_ERR; &#125; /* SELECT the new DB * * 首先写入 SELECT 命令，确保之后的数据会被插入到正确的数据库上 */ if (rioWrite(&amp;aof,selectcmd,sizeof(selectcmd)-1) == 0) goto werr; if (rioWriteBulkLongLong(&amp;aof,j) == 0) goto werr; /* Iterate this DB writing every entry * * 遍历数据库所有键，并通过命令将它们的当前状态（值）记录到新 AOF 文件中 */ while((de = dictNext(di)) != NULL) &#123; sds keystr; robj key, *o; long long expiretime; // 取出键 keystr = dictGetKey(de); // 取出值 o = dictGetVal(de); initStaticStringObject(key,keystr); // 取出过期时间 expiretime = getExpire(db,&amp;key); /* If this key is already expired skip it * * 如果键已经过期，那么跳过它，不保存 */ if (expiretime != -1 &amp;&amp; expiretime &lt; now) continue; /* Save the key and associated value * * 根据值的类型，选择适当的命令来保存值 */ if (o-&gt;type == REDIS_STRING) &#123; /* Emit a SET command */ char cmd[]="*3\r\n$3\r\nSET\r\n"; if (rioWrite(&amp;aof,cmd,sizeof(cmd)-1) == 0) goto werr; /* Key and value */ if (rioWriteBulkObject(&amp;aof,&amp;key) == 0) goto werr; if (rioWriteBulkObject(&amp;aof,o) == 0) goto werr; &#125; else if (o-&gt;type == REDIS_LIST) &#123; if (rewriteListObject(&amp;aof,&amp;key,o) == 0) goto werr; &#125; else if (o-&gt;type == REDIS_SET) &#123; if (rewriteSetObject(&amp;aof,&amp;key,o) == 0) goto werr; &#125; else if (o-&gt;type == REDIS_ZSET) &#123; if (rewriteSortedSetObject(&amp;aof,&amp;key,o) == 0) goto werr; &#125; else if (o-&gt;type == REDIS_HASH) &#123; if (rewriteHashObject(&amp;aof,&amp;key,o) == 0) goto werr; &#125; else &#123; redisPanic("Unknown object type"); &#125; /* Save the expire time * * 保存键的过期时间 */ if (expiretime != -1) &#123; char cmd[]="*3\r\n$9\r\nPEXPIREAT\r\n"; // 写入 PEXPIREAT expiretime 命令 if (rioWrite(&amp;aof,cmd,sizeof(cmd)-1) == 0) goto werr; if (rioWriteBulkObject(&amp;aof,&amp;key) == 0) goto werr; if (rioWriteBulkLongLong(&amp;aof,expiretime) == 0) goto werr; &#125; &#125; // 释放迭代器 dictReleaseIterator(di); &#125; /* Make sure data will not remain on the OS's output buffers */ // 冲洗并关闭新 AOF 文件 if (fflush(fp) == EOF) goto werr; if (aof_fsync(fileno(fp)) == -1) goto werr; if (fclose(fp) == EOF) goto werr; /* Use RENAME to make sure the DB file is changed atomically only * if the generate DB file is ok. * * 原子地改名，用重写后的新 AOF 文件覆盖旧 AOF 文件 */ if (rename(tmpfile,filename) == -1) &#123; redisLog(REDIS_WARNING,"Error moving temp append only file on the final destination: %s", strerror(errno)); unlink(tmpfile); return REDIS_ERR; &#125; redisLog(REDIS_NOTICE,"SYNC append only file rewrite performed"); return REDIS_OK;werr: fclose(fp); unlink(tmpfile); redisLog(REDIS_WARNING,"Write error writing append only file on disk: %s", strerror(errno)); if (di) dictReleaseIterator(di); return REDIS_ERR;&#125; 同步函数会阻塞，逻辑和rdb差不多。逻辑来说分析和解析当前的aof文件，对每个key的命令做合并是合理的方式，但是可能会有跨度太大等风险重写是从key中直接读值的方式来完成。 aof backgroundaof background 也是fork一个进程去完成操作。但是和rdb不同的是aof有个增量的不一致问题。rdb仅仅是记录快照。 解决方案：在执行命令的时候在aof缓冲区和rewrite aof 缓冲区都会写一份。(在aof调用的相同的地方。通过判定子进程id)12345678910111213141516171819202122232425262728293031323334353637383940414243444546/* Append data to the AOF rewrite buffer, allocating new blocks if needed. */void aofRewriteBufferAppend(unsigned char *s, unsigned long len) &#123; listNode *ln = listLast(server.aof_rewrite_buf_blocks); aofrwblock *block = ln ? ln-&gt;value : NULL; while(len) &#123; /* If we already got at least an allocated block, try appending * at least some piece into it. */ if (block) &#123; unsigned long thislen = (block-&gt;free &lt; len) ? block-&gt;free : len; if (thislen) &#123; /* The current block is not already full. */ memcpy(block-&gt;buf+block-&gt;used, s, thislen); block-&gt;used += thislen; block-&gt;free -= thislen; s += thislen; len -= thislen; &#125; &#125; if (len) &#123; /* First block to allocate, or need another block. */ int numblocks; block = zmalloc(sizeof(*block)); block-&gt;free = AOF_RW_BUF_BLOCK_SIZE; block-&gt;used = 0; listAddNodeTail(server.aof_rewrite_buf_blocks,block); /* Log every time we cross more 10 or 100 blocks, respectively * as a notice or warning. */ numblocks = listLength(server.aof_rewrite_buf_blocks); if (((numblocks+1) % 10) == 0) &#123; int level = ((numblocks+1) % 100) == 0 ? LL_WARNING : LL_NOTICE; serverLog(level,"Background AOF buffer size: %lu MB", aofRewriteBufferSize()/(1024*1024)); &#125; &#125; &#125; /* Install a file event to send data to the rewrite child if there is * not one already. */ if (aeGetFileEvents(server.el,server.aof_pipe_write_data_to_child) == 0) &#123; aeCreateFileEvent(server.el, server.aof_pipe_write_data_to_child, AE_WRITABLE, aofChildWriteDiffData, NULL); &#125;&#125; 等待aof重写完成后，全都flush到aof文件中去。1234567891011121314151617181920212223// 为何不用sds，担心buf溢出？ssize_t aofRewriteBufferWrite(int fd) &#123; listNode *ln; listIter li; ssize_t count = 0; listRewind(server.aof_rewrite_buf_blocks,&amp;li); //遍历缓存块 while((ln = listNext(&amp;li))) &#123; aofrwblock *block = listNodeValue(ln); ssize_t nwritten; if (block-&gt;used) &#123; nwritten = write(fd,block-&gt;buf,block-&gt;used); if (nwritten != (ssize_t)block-&gt;used) &#123; if (nwritten == 0) errno = EIO; return -1; &#125; count += nwritten; &#125; &#125; return count;&#125;]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis数据结构]]></title>
    <url>%2F2018%2F04%2F10%2Fredis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[字符串demo set msg demo demo 在底层创建的就是一个sds（simple dynamic string）字符串。sds 除了存储字符串之外，还会被用作各类缓冲区。 实现最新版本的sdshdr的代码如下1234567891011121314151617181920212223242526272829303132333435363738/* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. *///将 char定义成 sdstypedef char *sds;// sds headerstruct __attribute__ ((__packed__)) sdshdr5 &#123; unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; /* used */ // 申请空间， free = alloc - len，初始化时 alloc = len uint8_t alloc; /* excluding the header and null terminator */ // 通过type来判断使用哪种sds，进一步节省空间，sdshdr8 sdshdr16 sdshdr32 sdshdr64 unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr16 &#123; uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr32 &#123; uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr64 &#123; uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;sd redis设计与实现的代码1234567struct sdshdr &#123; int len; //源码中没有 替代的是alloc //todo 为什么要改动 int free; char[] buf;&#125; 与c语言字符串的区别 与c字符串相同用’\0’来做字符串的结尾。也就是说整个字符串的长度为 alloc + 1 (len + free + 1) c字符串没有len字段，每次获取len需要对整个的字符串遍历，是O(N)的时间复杂度。 c strcat(char dest,char src)，需要预分配内存，如果内存不够会引起报错，默认不会检查。sds因为知道字符串长度，会预检查，不会引发缓冲区溢出的问题。 字符串增减引起的问题 c字符串在拼接和缩短的时候需要重新分配内存，否则会产生内存溢出或者内存泄露的相关问题。 而重新分配空间涉及到系统调用，是个相对耗时的操作。 普通程序字符串不太可能频繁更改长度。所以重新分配内存是可以接受的。 redis数据库value会被相当频繁的修改，会产生性能问题。 字符串增减解决方案（其实就是空间换时间） 空间预分配 预分配sds所需要的额外的空间 当sds的长度小于1m，在扩展时会将free和len设置成等长（即字符串长度若为10，则free也为10，整个所占用空间为10+10+1（末尾的标志位））。 若大于1m，则free=1m,总长度为原始长度+1m+1 惰性空间释放 若缩短长度，则缩短的长度将会加入free之中 sds会在必要时刻真正释放未使用空间（书中没讲，代码找不到，可能是类似gc的机制？），调用的sdsfree方法。 sds二进制安全 c字符串用’\0’来标识字符串的结尾，所以字符串中如果含有’\0’就会出问题了。 sds 是一个buf来保存，不依赖’\0’，所以是二进制安全的。 兼容部分c字符串函数（’\0’结尾的目的） 链表demo lpush list_demo 1 2 3 4llen list_demo 源代码12345678910111213141516171819202122typedef struct listNode &#123; struct listNode *prev; struct listNode *next; void *value;&#125; listNode;typedef struct listIter &#123; listNode *next; int direction;&#125; listIter;typedef struct list &#123; listNode *head; listNode *tail; //节点复制函数 void *(*dup)(void *ptr); //节点释放函数 void (*free)(void *ptr); //节点对比函数 int (*match)(void *ptr, void *key); unsigned long len;&#125; list; 总结 带头尾指针，为了满足lpush &amp; rpush 双向链表，无环 字典（dict）demo set msg “hello world”hmset hash field1 value1 field2 value2 field3 value3 dict是一个用于维护key和value映射关系的数据结构 源代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253typedef struct dictEntry &#123; void *key; // 结构体只占一份数据空间 union &#123; void *val; uint64_t u64; int64_t s64; double d; &#125; v; struct dictEntry *next;&#125; dictEntry;typedef struct dictType &#123; uint64_t (*hashFunction)(const void *key); void *(*keyDup)(void *privdata, const void *key); void *(*valDup)(void *privdata, const void *obj); int (*keyCompare)(void *privdata, const void *key1, const void *key2); void (*keyDestructor)(void *privdata, void *key); void (*valDestructor)(void *privdata, void *obj);&#125; dictType;/* This is our hash table structure. Every dictionary has two of this as we * implement incremental rehashing, for the old to the new table. */typedef struct dictht &#123; dictEntry **table; unsigned long size; //用于将哈希值映射到table的位置索引。它的值等于(size-1)，比如7, 15, 31, 63，等等，也就是用二进制表示的各个bit全1的数字。每个key先经过hashFunction计算得到一个哈希值，然后计算(哈希值 &amp; sizemask)得到在table上的位置。相当于计算取余(哈希值 % size)。 unsigned long sizemask; //记录dict中现有的数据个数。它与size的比值就是装载因子（load factor）。这个比值越大，哈希值冲突概率越高。 unsigned long used;&#125; dictht;typedef struct dict &#123; dictType *type; void *privdata; /* 两个哈希表（ht[2]）。只有在重哈希的过程中，ht[0]和ht[1]才都有效。而在平常情况下，只有ht[0]有效，ht[1]里面没有任何数据。上图表示的就是重哈希进行到中间某一步时的情况。*/ dictht ht[2]; long rehashidx; /* rehashing not in progress if rehashidx == -1 */ unsigned long iterators; /* number of iterators currently running */&#125; dict;/* If safe is set to 1 this is a safe iterator, that means, you can call * dictAdd, dictFind, and other functions against the dictionary even while * iterating. Otherwise it is a non safe iterator, and only dictNext() * should be called while iterating. */typedef struct dictIterator &#123; dict *d; long index; int table, safe; dictEntry *entry, *nextEntry; /* unsafe iterator fingerprint for misuse detection. */ long long fingerprint;&#125; dictIterator; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/* Performs N steps of incremental rehashing. Returns 1 if there are still * keys to move from the old to the new hash table, otherwise 0 is returned. * * Note that a rehashing step consists in moving a bucket (that may have more * than one key as we use chaining) from the old to the new hash table, however * since part of the hash table may be composed of empty spaces, it is not * guaranteed that this function will rehash even a single bucket, since it * will visit at max N*10 empty buckets in total, otherwise the amount of * work it does would be unbound and the function may block for a long time. */int dictRehash(dict *d, int n) &#123; int empty_visits = n*10; /* Max number of empty buckets to visit. */ if (!dictIsRehashing(d)) return 0; // n &gt; 0 &amp;&amp; ht[0]不为空 while(n-- &amp;&amp; d-&gt;ht[0].used != 0) &#123; dictEntry *de, *nextde; /* Note that rehashidx can't overflow as we are sure there are more * elements because ht[0].used != 0 */ assert(d-&gt;ht[0].size &gt; (unsigned long)d-&gt;rehashidx); //遍历每个hash桶 while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) &#123; d-&gt;rehashidx++; // 倘若本次rehash 完成了 则 empty_visits == 0 if (--empty_visits == 0) return 1; &#125; de = d-&gt;ht[0].table[d-&gt;rehashidx]; /* Move all the keys in this bucket from the old to the new hash HT */ while(de) &#123; uint64_t h; nextde = de-&gt;next; /* Get the index in the new hash table */ h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask; de-&gt;next = d-&gt;ht[1].table[h]; d-&gt;ht[1].table[h] = de; d-&gt;ht[0].used--; d-&gt;ht[1].used++; de = nextde; &#125; d-&gt;ht[0].table[d-&gt;rehashidx] = NULL; d-&gt;rehashidx++; &#125; /* Check if we already rehashed the whole table... */ if (d-&gt;ht[0].used == 0) &#123; zfree(d-&gt;ht[0].table); d-&gt;ht[0] = d-&gt;ht[1]; _dictReset(&amp;d-&gt;ht[1]); d-&gt;rehashidx = -1; return 0; &#125; /* More to rehash... */ return 1;&#125; 采用的是增量式rehash java使用的是一次性rehash redis为了单次插入的时间，决定将rehash分布到多个操作之中，每次只rehash10个，同时增删改查都会启动rehash操作 rehash会导致数据分布在两个不同的table里，查询的时候也会轮训两个table，只有在table[0]找不到的情况下才回去找table[1] 插入数据时候会直接插入到table[1] 哈希表的扩展与收缩 服务器没有执行BGSAVE OR BGREWRITEOF 命令，而且哈希表的负载因子大于等于1. 服务器目前正在执行BGSAVE OR BGREWRITEOF 命令，且哈希表的负载因子大于等于5.（copy on write 的时候尽量避免扩展，节省内存） 当负载因子小于0.1时，程序自动开始对哈希表进行收缩操作。 robjdemoredis 会根据不同的输入值选择不同的数据结构key 和 value 都是使用的robj（reference count 最开始不明白value会在什么时候复用，后面发现blpop会复用key） set int_key 1set str_key str 底层是有robj来控制的数据结构类型 源码1234567891011121314151617181920212223242526272829/* Object types */#define OBJ_STRING 0#define OBJ_LIST 1#define OBJ_SET 2#define OBJ_ZSET 3#define OBJ_HASH 4/* Objects encoding. Some kind of objects like Strings and Hashes can be * internally represented in multiple ways. The 'encoding' field of the object * is set to one of this fields for this object. */#define OBJ_ENCODING_RAW 0 /* Raw representation */#define OBJ_ENCODING_INT 1 /* Encoded as integer */#define OBJ_ENCODING_HT 2 /* Encoded as hash table */#define OBJ_ENCODING_ZIPMAP 3 /* Encoded as zipmap */#define OBJ_ENCODING_LINKEDLIST 4 /* Encoded as regular linked list */#define OBJ_ENCODING_ZIPLIST 5 /* Encoded as ziplist */#define OBJ_ENCODING_INTSET 6 /* Encoded as intset */#define OBJ_ENCODING_SKIPLIST 7 /* Encoded as skiplist */#define OBJ_ENCODING_EMBSTR 8 /* Embedded sds string encoding */#define OBJ_ENCODING_QUICKLIST 9 /* Encoded as linked list of ziplists */#define LRU_BITS 24typedef struct redisObject &#123; unsigned type:4; unsigned encoding:4; unsigned lru:LRU_BITS; /* lru time (relative to server.lruclock) */ int refcount; void *ptr;&#125; robj; 这段代码执行的操作比较复杂，我们有必要仔细看一下每一步的操作： 第1步检查，检查type。确保只对string类型的对象进行操作。 第2步检查，检查encoding。sdsEncodedObject是定义在server.h中的一个宏，确保只对OBJ_ENCODING_RAW和OBJ_ENCODING_EMBSTR编码的string对象进行操作。这两种编码的string都采用sds来存储，可以尝试进一步编码处理。 #define sdsEncodedObject(objptr) (objptr-&gt;encoding == OBJ_ENCODING_RAW || objptr-&gt;encoding == OBJ_ENCODING_EMBSTR) 第3步检查，检查refcount。引用计数大于1的共享对象，在多处被引用。由于编码过程结束后robj的对象指针可能会变化（我们在前一篇介绍sdscatlen函数的时候提到过类似这种接口使用模式），这样对于引用计数大于1的对象，就需要更新所有地方的引用，这不容易做到。因此，对于计数大于1的对象不做编码处理。试图将字符串转成64位的long。64位的long所能表达的数据范围是-2^63到2^63-1，用十进制表达出来最长是20位数（包括负号）。这里判断小于等于21，似乎是写多了，实际判断小于等于20就够了（如果我算错了请一定告诉我哦）。string2l如果将字符串转成long转成功了，那么会返回1并且将转好的long存到value变量里。在转成long成功时，又分为两种情况。第一种情况：如果Redis的配置不要求运行LRU替换算法，且转成的long型数字的值又比较小（小于OBJ_SHARED_INTEGERS，在目前的实现中这个值是10000），那么会使用共享数字对象来表示。之所以这里的判断跟LRU有关，是因为LRU算法要求每个robj有不同的lru字段值，所以用了LRU就不能共享robj。shared.integers是一个长度为10000的数组，里面预存了10000个小的数字对象。这些小数字对象都是encoding = OBJ_ENCODING_INT的string robj对象。第二种情况：如果前一步不能使用共享小对象来表示，那么将原来的robj编码成encoding = OBJ_ENCODING_INT，这时ptr字段直接存成这个long型的值。注意ptr字段本来是一个void *指针（即存储的是内存地址），因此在64位机器上有64位宽度，正好能存储一个64位的long型值。这样，除了robj本身之外，它就不再需要额外的内存空间来存储字符串值。接下来是对于那些不能转成64位long的字符串进行处理。最后再做两步处理：如果字符串长度足够小（小于等于OBJ_ENCODING_EMBSTR_SIZE_LIMIT，定义为44），那么调用createEmbeddedStringObject编码成encoding = OBJ_ENCODING_EMBSTR；如果前面所有的编码尝试都没有成功（仍然是OBJ_ENCODING_RAW），且sds里空余字节过多，那么做最后一次努力，调用sds的sdsRemoveFreeSpace接口来释放空余字节。 append和setbit命令的实现中，.c中的dbUnshareStringValue函数，将string对象的内部编码转成OBJ_ENCODING_RAW的（只有这种编码的robj对象，其内部的sds 才能在后面自由追加新的内容），并解除可能存在的对象共享状态。这里面调用了前面提到的getDecodedObject。 关于embstr 如果字符串长度小于39字节（详细解释）,则会使用embstr模式 embstr和raw一样都会使用robj和sdshdr结构来表示字符串对象，但是raw会调用两次来创建robj和sdshdr结构，embstr则通过一次内存调用分配一块连续的空间。 跳跃表demo zadd key 1 member1 2 member2 当数据较少时，sorted set是由一个ziplist来实现的。 当数据多的时候，sorted set是由一个dict + 一个skiplist来实现的。简单来讲，dict用来查询数据到分数的对应关系，而skiplist用来根据分数查询数据（可能是范围查找）。12345typedef struct zset &#123; // 用于score的o1操作 dict *dict; zskiplist *zsl;&#125; zset; 1234567891011121314151617int zsetScore(robj *zobj, sds member, double *score) &#123; if (!zobj || !member) return C_ERR; //从ziplist中获取 if (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123; if (zzlFind(zobj-&gt;ptr, member, score) == NULL) return C_ERR; &#125; else if (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123; zset *zs = zobj-&gt;ptr; //从dict中获取 dictEntry *de = dictFind(zs-&gt;dict, member); if (de == NULL) return C_ERR; *score = *(double*)dictGetVal(de); &#125; else &#123; serverPanic("Unknown sorted set encoding"); &#125; return C_OK;&#125; 源代码123456789101112131415161718typedef struct zskiplistNode &#123; robj *obj; // 分值 ，被共享到dict中 double score; struct zskiplistNode *backward; struct zskiplistLevel &#123; struct zskiplistNode *forward; //用于计算rank，表示当前指针跨越了多少个节点 unsigned int span; &#125; level[];&#125; zskiplistNode;typedef struct zskiplist &#123; struct zskiplistNode *header, *tail; // 节点长度 unsigned long length; int level;&#125; zskiplist; 疑问关于span在更新的时候需要遍历整个数组去整个遍历span的值，这样会不会有损效率update[i]是同一层的前驱节点123456789101112131415161718192021222324252627282930if (level &gt; zsl-&gt;level) &#123; //超过skiplist level for (i = zsl-&gt;level; i &lt; level; i++) &#123; rank[i] = 0; update[i] = zsl-&gt;header; //感觉像是简单的初始化，值不对 update[i]-&gt;level[i].span = zsl-&gt;length; &#125; zsl-&gt;level = level;&#125;x = zslCreateNode(level,score,obj);// 小于当前插入level的for (i = 0; i &lt; level; i++) &#123; x-&gt;level[i].forward = update[i]-&gt;level[i].forward; update[i]-&gt;level[i].forward = x; /* update span covered by update[i] as x is inserted here */ // 原有的span被分隔了 // 当前节点 x-&gt;level[i].span = update[i]-&gt;level[i].span - (rank[0] - rank[i]); // 上一个节点 update[i]-&gt;level[i].span = (rank[0] - rank[i]) + 1;&#125;/* increment span for untouched levels */// 大于levelfor (i = level; i &lt; zsl-&gt;level; i++) &#123; // 因为新节点高度不够，所以span+1即可 update[i]-&gt;level[i].span++;&#125; 转换 zset-max-ziplist-entries 128zset-max-ziplist-value 64 当sorted set中的元素个数，即(数据, score)对的数目超过128的时候，也就是ziplist数据项超过256的时候。当sorted set中插入的任意一个数据的长度超过了64的时候。 整数集合demo sadd numbers 1 3 5 7object encoding numbers intset ：整数集合 源代码12345typedef struct intset &#123; uint32_t encoding; uint32_t length; int8_t contents[];&#125; intset; encoding分为 8 16 32 64，目的用于节约内存 假如原来的encoding不能容纳新的数据，将会进行一次升级，encoding会升级成新数据的大小，由于空间是2的指数倍扩展的，挪动相对容易 整个数组不支持降级操作。 压缩列表（ziplist）demo rpush 1st 1 3 5 10086 “hello” “world”object encoding 1stquicklist 默认配置下是quicklist（以上是redis的设计与实现的例子） 127.0.0.1:6379&gt; hmset ziplist key1 value1 key2 value2OK127.0.0.1:6379&gt; object encoding ziplist“ziplist” 而hash的表现很正常 问题在哪看了一下2.8的源代码2.8版本12345678910111213141516171819202122232425262728void pushGenericCommand(redisClient *c, int where) &#123; int j, waiting = 0, pushed = 0; robj *lobj = lookupKeyWrite(c-&gt;db,c-&gt;argv[1]); if (lobj &amp;&amp; lobj-&gt;type != REDIS_LIST) &#123; addReply(c,shared.wrongtypeerr); return; &#125; for (j = 2; j &lt; c-&gt;argc; j++) &#123; c-&gt;argv[j] = tryObjectEncoding(c-&gt;argv[j]); if (!lobj) &#123; // 关键代码 lobj = createZiplistObject(); dbAdd(c-&gt;db,c-&gt;argv[1],lobj); &#125; listTypePush(lobj,c-&gt;argv[j],where); pushed++; &#125; addReplyLongLong(c, waiting + (lobj ? listTypeLength(lobj) : 0)); if (pushed) &#123; char *event = (where == REDIS_HEAD) ? "lpush" : "rpush"; signalModifiedKey(c-&gt;db,c-&gt;argv[1]); notifyKeyspaceEvent(REDIS_NOTIFY_LIST,event,c-&gt;argv[1],c-&gt;db-&gt;id); &#125; server.dirty += pushed;&#125; 3.2版本1234567891011121314151617181920212223242526272829void pushGenericCommand(client *c, int where) &#123; int j, pushed = 0; robj *lobj = lookupKeyWrite(c-&gt;db,c-&gt;argv[1]); if (lobj &amp;&amp; lobj-&gt;type != OBJ_LIST) &#123; addReply(c,shared.wrongtypeerr); return; &#125; for (j = 2; j &lt; c-&gt;argc; j++) &#123; if (!lobj) &#123; // 关键代码 lobj = createQuicklistObject(); quicklistSetOptions(lobj-&gt;ptr, server.list_max_ziplist_size, server.list_compress_depth); dbAdd(c-&gt;db,c-&gt;argv[1],lobj); &#125; listTypePush(lobj,c-&gt;argv[j],where); pushed++; &#125; addReplyLongLong(c, (lobj ? listTypeLength(lobj) : 0)); if (pushed) &#123; char *event = (where == LIST_HEAD) ? "lpush" : "rpush"; signalModifiedKey(c-&gt;db,c-&gt;argv[1]); notifyKeyspaceEvent(NOTIFY_LIST,event,c-&gt;argv[1],c-&gt;db-&gt;id); &#125; server.dirty += pushed;&#125; 初始化的时候直接生成了quicklist，而直接去除了2.8的ziplist的设计。 1234567891011121314# Lists are also encoded in a special way to save a lot of space.# The number of entries allowed per internal list node can be specified# as a fixed maximum size or a maximum number of elements.# For a fixed maximum size, use -5 through -1, meaning:# -5: max size: 64 Kb &lt;-- not recommended for normal workloads# -4: max size: 32 Kb &lt;-- not recommended# -3: max size: 16 Kb &lt;-- probably not recommended# -2: max size: 8 Kb &lt;-- good# -1: max size: 4 Kb &lt;-- good# Positive numbers mean store up to _exactly_ that number of elements# per list node.# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),# but if your use case is unique, adjust the settings as necessary.list-max-ziplist-size -2 上述配置看起来是遗留问题（当时是那么认为的，后面发现了quicklist，2.8代码里统一用的ziplist，quicklist是优化方案） 理解ziplist是一个经过特殊编码的双向链表，它的设计目标就是为了提高存储效率。ziplist可以用于存储字符串或整数，其中整数是按真正的二进制表示进行编码的，而不是编码成字符串序列。它能以O(1)的时间复杂度在表的两端提供push和pop操作。 ziplist充分体现了Redis对于存储效率的追求。一个普通的双向链表，链表中每一项都占用独立的一块内存，各项之间用地址指针（或引用）连接起来。这种方式会带来大量的内存碎片，而且地址指针也会占用额外的内存。而ziplist却是将表中每一项存放在前后连续的地址空间内，一个ziplist整体占用一大块内存。它是一个表（list），但其实不是一个链表（linked list）。 数据结构 … 各个部分在内存上是前后相邻的，它们分别的含义如下： : 32bit，表示ziplist占用的字节总数（也包括本身占用的4个字节）。 : 32bit，表示ziplist表中最后一项（entry）在ziplist中的偏移字节数。的存在，使得我们可以很方便地找到最后一项（不用遍历整个ziplist），从而可以在ziplist尾端快速地执行push或pop操作。 : 16bit， 表示ziplist中数据项（entry）的个数。zllen字段因为只有16bit，所以可以表达的最大值为2^16-1。这里需要特别注意的是，如果ziplist中数据项个数超过了16bit能表达的最大值，ziplist仍然可以来表示。那怎么表示呢？这里做了这样的规定：如果小于等于2^16-2（也就是不等于2^16-1），那么就表示ziplist中数据项的个数；否则，也就是等于16bit全为1的情况，那么就不表示数据项个数了，这时候要想知道ziplist中数据项总数，那么必须对ziplist从头到尾遍历各个数据项，才能计数出来。 : 表示真正存放数据的数据项，长度不定。一个数据项（entry）也有它自己的内部结构，这个稍后再解释。 : ziplist最后1个字节，是一个结束标记，值固定等于255。 entry数据结构 : 表示前一个数据项占用的总字节数。这个字段的用处是为了让ziplist能够从后向前遍历（从后一项的位置，只需向前偏移prevrawlen个字节，就找到了前一项）。这个字段采用变长编码。（类似与一个向前指针，标识长度可能是因为比指针更加节省内存） : 表示当前数据项的数据长度（即部分的长度）。也采用变长编码。 源代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889static unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) &#123; size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), reqlen; unsigned int prevlensize, prevlen = 0; size_t offset; int nextdiff = 0; unsigned char encoding = 0; long long value = 123456789; /* initialized to avoid warning. Using a value that is easy to see if for some reason we use it uninitialized. */ zlentry tail; /* Find out prevlen for the entry that is inserted. */ if (p[0] != ZIP_END) &#123; ZIP_DECODE_PREVLEN(p, prevlensize, prevlen); &#125; else &#123; unsigned char *ptail = ZIPLIST_ENTRY_TAIL(zl); if (ptail[0] != ZIP_END) &#123; prevlen = zipRawEntryLength(ptail); &#125; &#125; /* See if the entry can be encoded */ if (zipTryEncoding(s,slen,&amp;value,&amp;encoding)) &#123; /* 'encoding' is set to the appropriate integer encoding */ reqlen = zipIntSize(encoding); &#125; else &#123; /* 'encoding' is untouched, however zipEncodeLength will use the * string length to figure out how to encode it. */ reqlen = slen; &#125; /* We need space for both the length of the previous entry and * the length of the payload. */ reqlen += zipPrevEncodeLength(NULL,prevlen); reqlen += zipEncodeLength(NULL,encoding,slen); /* When the insert position is not equal to the tail, we need to * make sure that the next entry can hold this entry's length in * its prevlen field. */ nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0; /* Store offset because a realloc may change the address of zl. */ offset = p-zl; zl = ziplistResize(zl,curlen+reqlen+nextdiff); p = zl+offset; /* Apply memory move when necessary and update tail offset. */ if (p[0] != ZIP_END) &#123; /* Subtract one because of the ZIP_END bytes */ memmove(p+reqlen,p-nextdiff,curlen-offset-1+nextdiff); /* Encode this entry's raw length in the next entry. */ zipPrevEncodeLength(p+reqlen,reqlen); /* Update offset for tail */ ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+reqlen); /* When the tail contains more than one entry, we need to take * "nextdiff" in account as well. Otherwise, a change in the * size of prevlen doesn't have an effect on the *tail* offset. */ zipEntry(p+reqlen, &amp;tail); if (p[reqlen+tail.headersize+tail.len] != ZIP_END) &#123; ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+nextdiff); &#125; &#125; else &#123; /* This element will be the new tail. */ ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(p-zl); &#125; /* When nextdiff != 0, the raw length of the next entry has changed, so * we need to cascade the update throughout the ziplist */ if (nextdiff != 0) &#123; offset = p-zl; zl = __ziplistCascadeUpdate(zl,p+reqlen); p = zl+offset; &#125; /* Write the entry */ p += zipPrevEncodeLength(p,prevlen); p += zipEncodeLength(p,encoding,slen); if (ZIP_IS_STR(encoding)) &#123; memcpy(p,s,slen); &#125; else &#123; zipSaveInteger(p,value,encoding); &#125; ZIPLIST_INCR_LENGTH(zl,1); return zl;&#125; 这个函数是在指定的位置p插入一段新的数据，待插入数据的地址指针是s，长度为slen。插入后形成一个新的数据项，占据原来p的配置，原来位于p位置的数据项以及后面的所有数据项，需要统一向后移动，给新插入的数据项留出空间。参数p指向的是ziplist中某一个数据项的起始位置，或者在向尾端插入的时候，它指向ziplist的结束标记每次插入需要计算数据长度，如果超过长度可能会引发拷贝,重新调用内存的分配。 运用 hash-max-ziplist-entries 512hash-max-ziplist-value 64 随着数据的变大，ziplist会转换成dict（hash结构） 每次插入或者修改可能会引发内存拷贝性能很差。 一旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更大的一块数据。 当ziplist数据项过多的时候，在它上面查找指定的数据项就会性能变得很低，因为ziplist上的查找需要进行遍历。 quicklist（为了更好的支持list，优化版本的ziplist）demodemo 和 配置 在ziplist中有 理解list具有这样的一些特点：它是一个能维持数据项先后顺序的列表（各个数据项的先后顺序由插入位置决定），便于在表的两端追加和删除数据，而对于中间位置的存取具有O(N)的时间复杂度。 为了解决 源代码1234567891011121314151617181920212223242526typedef struct quicklistNode &#123; struct quicklistNode *prev; struct quicklistNode *next; unsigned char *zl; //和ziplist的结构一样，指向一个ziplist unsigned int sz; /* ziplist size in bytes */ unsigned int count : 16; /* count of items in ziplist */ unsigned int encoding : 2; /* RAW==1 or LZF==2 */ unsigned int container : 2; /* NONE==1 or ZIPLIST==2 */ unsigned int recompress : 1; /* was this node previous compressed? */ unsigned int attempted_compress : 1; /* node can't compress; too small */ unsigned int extra : 10; /* more bits to steal for future usage */&#125; quicklistNode;typedef struct quicklistLZF &#123; unsigned int sz; /* LZF size in bytes*/ char compressed[];&#125; quicklistLZF;//这其实就是一个很简单的头尾的链表结构typedef struct quicklist &#123; quicklistNode *head; quicklistNode *tail; unsigned long count; /* total count of all entries in all ziplists */ unsigned int len; /* number of quicklistNodes */ int fill : 16; /* fill factor for individual nodes */ unsigned int compress : 16; /* depth of end nodes not to compress;0=off */&#125; quicklist; 解决的问题 双向链表便于在表的两端进行push和pop操作，但是它的内存开销比较大。首先，它在每个节点上除了要保存数据之外，还要额外保存两个指针；其次，双向链表的各个节点是单独的内存块，地址不连续，节点多了容易产生内存碎片。 ziplist由于是一整块连续内存，所以存储效率很高。但是，它不利于修改操作，每次数据变动都会引发一次内存的realloc。特别是当ziplist长度很长的时候，一次realloc可能会导致大批量的数据拷贝，进一步降低性能。 存储结构的优化 每个quicklist节点上的ziplist越短，则内存碎片越多。内存碎片多了，有可能在内存中产生很多无法被利用的小碎片，从而降低存储效率。这种情况的极端是每个quicklist节点上的ziplist只包含一个数据项，这就蜕化成一个普通的双向链表了。 每个quicklist节点上的ziplist越长，则为ziplist分配大块连续内存空间的难度就越大。有可能出现内存里有很多小块的空闲空间（它们加起来很多），但却找不到一块足够大的空闲空间分配给ziplist的情况。这同样会降低存储效率。这种情况的极端是整个quicklist只有一个节点，所有的数据项都分配在这仅有的一个节点的ziplist里面。这其实蜕化成一个ziplist了。 push逻辑 当插入位置所在的ziplist大小没有超过限制时，直接插入到ziplist中就好了； 当插入位置所在的ziplist大小超过了限制，但插入的位置位于ziplist两端，并且相邻的quicklist链表节点的ziplist大小没有超过限制，那么就转而插入到相邻的那个quicklist链表节点的ziplist中； 当插入位置所在的ziplist大小超过了限制，但插入的位置位于ziplist两端，并且相邻的quicklist链表节点的ziplist大小也超过限制，这时需要新创建一个quicklist链表节点插入。 对于插入位置所在的ziplist大小超过了限制的其它情况（主要对应于在ziplist中间插入数据的情况），则需要把当前ziplist分裂为两个节点，然后再其中一个节点上插入数据。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017~2018赛季]]></title>
    <url>%2F2018%2F01%2F27%2F2017-2018%E8%B5%9B%E5%AD%A3%2F</url>
    <content type="text"><![CDATA[最近心血来潮阅读redis源码的时候才发现整个的知识结构还是零零散散，零散到连蒙带猜都没有办法串联起整个大致的流程。细节方面更是一团糟，网络，内核操作，数据结构就和没学过一样，cpp的基础也忘得差不多了。回想一年来确实在逻辑上有了很大的退步，看disruptor看了个一知半解，连worker这种重要的东西都直接忽略了，barrier看上去很复杂的东西了解个思路，也没有仔细钻研了。好像也就听说了ringbuffer这个名词了。很多框架看了一半也就没有再看了，最多就是看了下博文了解了一下api，最多再看个大致流程，完事了。有人和我说是缺乏耐心，也可能是年纪大了，思维比不上从前了。我觉得更多的还是大脑缺乏锻炼了吧，沉迷于没有必要的扯淡和调侃，渐渐地有了一种比下有余的感觉，也可能是真的害怕去深入的学习一些东西，在深入讨论的时候露出马脚，用我还没来得及看源码这种借口来掩饰自己的恐惧。现在觉得没啥可恐惧的了，反正都不会，从头开始呗，放下包袱，重头开始好好整理一下。还有一个多月就要迈入26岁了，在这之前尽量做出一些改变吧，改变一下这种菜的可怕而又沾沾自喜的状态。静下心来去看一些东西，毕竟像我这样的菜鸡不翻开书，不拿起笔，感觉什么学都不会。Push自己一把总是没错的，专注一点，很多事情只会吹牛逼是不够的！]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[[转载]redis-debug]]></title>
    <url>%2F2018%2F01%2F11%2F%E8%BD%AC%E8%BD%BD-redis-debug%2F</url>
    <content type="text"><![CDATA[转载自 https://liuzhengyang.github.io/2017/08/13/debug-redis/感谢大佬，之后学习一下c 背景redis常用于作为缓存，用来缓存热点数据。一些数据例如视频网站的视频、评论等信息，这些信息有着比较明显的时间上的冷热区分，即最近发布的最有可能访问到，最热门的一些数据往往只占很小一部分，所以可以利用缓存减少响应时间和数据库的压力。 学习使用redis，除了常用的基本命令、数据结构外，还需要了解其实现机制能够帮助更好的使用它，另外一些最佳实践和容易踩坑的地方也需要多注意。 下载、编译、运行、debug基本上入门学习、了解一个新的框架、工具开始就是这些步骤，搭配上一些官方wiki、博客、文章、书籍更好了。但是从未入门到入门经常有一个小门槛，比较编译，可能因为平台、环境等因素遇到各种各样的问题，让我们感到气馁甚至放弃，所以本文期望能够给一些朋友减少入门的阻力。 Clion熟悉IDEA的同学推荐使用CLion查看、debugC、C++代码，使用gdb、lldb等也可以。 1git clone https://github.com/antirez/redis Import redis project using CLion 打开后，略微修改CMakeList.txt文件, 修改为CMakeList.txt 然后在redis文件夹下执行make进行编译 1make 12cd srcsh mkreleasehdr.sh 然后Clion上会出现一个server的debug按钮，但是在我的环境下执行会出现错误， 12ld: symbol(s) not found for architecture x86_64clang: error: linker command failed with exit code 1 (use -v to see invocation) 改为在命令行执行如下命令后就好了。注意路径要修改为自己的路径。 1cmake --build ./cmake-build-debug --target redis -- -j 4 -stdlib=libstdc++ 然后使用server debug就可以了。 VisualStudioCode最近发现VisualStudioCode也很好用，对C++的支持比Clion要好一些下载好VisualStudioCode后，安装C++的插件。然后在debug里添加新的configuration。会出现一个配置文件关键的program，这里填要debug的target，在redis里就是编译后的src/redis-server，然后点击debug就可以了。 123456789101112131415161718&#123; &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;(lldb) Launch&quot;, &quot;type&quot;: &quot;cppdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;$&#123;workspaceRoot&#125;/src/redis-server&quot;, &quot;args&quot;: [], &quot;stopAtEntry&quot;: false, &quot;cwd&quot;: &quot;$&#123;workspaceRoot&#125;&quot;, &quot;environment&quot;: [], &quot;externalConsole&quot;: true, &quot;MIMode&quot;: &quot;lldb&quot; &#125; ]&#125;]]></content>
      <categories>
        <category>tips</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring代理]]></title>
    <url>%2F2018%2F01%2F03%2FSpring%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[spring代理问题问题还是起于老掉牙的spring @Transactional 同类调用不生效的问题。以下的场景都基于method1调用method2，@Transactional 是加载method2上，外部调用调用的是method1接口。大致结构如下 12345678910public void method1() &#123; System.out.println("do in method 1"); method2();&#125;@Transactionalpublic void method2() &#123; System.out.println("do in method 2");&#125; 以前一直对于这个问题懵懵懂懂，现在彻底的来搞明白这个事情。 疑问对于jdk动态代理，其实问题一直很明白，因为jdk动态代理生成的proxy是继承自java.lang.reflect.Proxy，反射到目标类去执行，而在目标类的内部调用中是无法再回到代理类的，所以 @Transactional 在同类调用之间无效。 但是cglib生成的是目标类的子类，猜想的结构大概是这样的。1234567891011121314151617181920212223242526272829303132//猜想的cglib生成类简易写法public class GuessedCglibProxy extends SimpleCglibService &#123; @Override public void method1() &#123; System.out.println("GuessedCglibProxy in method1"); super.method1(); &#125; @Override public void method2() &#123; System.out.println("GuessedCglibProxy in method2"); super.method2(); &#125;&#125;public class SimpleCglibService &#123; public void method1() &#123; System.out.println("SimpleCglibService in method1"); method2(); &#125; public void method2() &#123; System.out.println("SimpleCglibService in method2"); &#125; public static void main(String[] args) &#123; GuessedCglibProxy guessedCglibProxy = new GuessedCglibProxy(); guessedCglibProxy.method1(); &#125;&#125; 这样理论上应该是能够调用到代理类的。但是事实是并不能调用成功。找了一下Spring文档也发现了相关的结论。 Note: In proxy mode (which is the default), only ‘external’ method calls coming in through the proxy will be intercepted. This means that ‘self-invocation’, i.e. a method within the target object calling some other method of the target object, won’t lead to an actual transaction at runtime even if the invoked method is marked with @Transactional! Consider the use of AspectJ mode (see below) if you expect self-invocations to be wrapped with transactions as well. In this case, there won’t be a proxy in the first place; instead, the target class will be ‘weaved’ (i.e. its byte code will be modified) in order to turn @Transactional into runtime behavior on any kind of method. 重新梳理一下知识点。那么究竟问题在哪。 jdk动态代理jdk动态代理调用栈 jdk动态代理demo代码测试代码地址 先看下简易的动态代理的代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public interface SimpleService &#123; void method1(); void method2();&#125;public class SimpleServiceImpl implements SimpleService &#123; @Override public void method1() &#123; System.out.println("do in method 1"); method2(); &#125; @Override public void method2() &#123; System.out.println("do in method 2"); &#125; public static void main(String[] args) &#123; //生成jdk动态代理的方法 ProxyUtils.generateClassFile(SimpleService.class, "SimpleServiceJavaDynamicProxy"); SimpleService simpleService = new SimpleServiceImpl(); SimpleService simpleServiceImpl = SimpleServiceProxy.proxy(SimpleService.class, simpleService); simpleServiceImpl.method1(); &#125;&#125;public class SimpleServiceProxyHandler implements InvocationHandler &#123; //invoke 方法并不提供impl的实例，因为proxy在生成的时候是与impl无关的，所以这里需要自己塞进去 private Object target; public SimpleServiceProxyHandler(Object target) &#123; this.target = target; &#125; // 方法需要自定义 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("in proxy, class : " + target.getClass().getName() + " ,method : " + method.getName()); return method.invoke(target, args); &#125;&#125;public class SimpleServiceProxy &#123; //构建代理类，详细分析下面会有 public static &lt;T&gt; T proxy(final Class&lt;T&gt; interfaceClass, T target) &#123; return (T) Proxy.newProxyInstance(interfaceClass.getClassLoader(), new Class&lt;?&gt;[]&#123;interfaceClass&#125;, new SimpleServiceProxyHandler(target)); &#125;&#125;public class ProxyUtils &#123; // 动态代理类落地的方法。 // 一般都是在target同类的目录下 public static void generateClassFile(Class clazz,String proxyName)&#123; byte[] classFile = ProxyGenerator.generateProxyClass(proxyName, clazz.getInterfaces()); String paths = clazz.getResource(".").getPath(); System.out.println(paths); FileOutputStream out = null; try &#123; out = new FileOutputStream(paths+proxyName+".class"); out.write(classFile); out.flush(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; out.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; Jdk动态代理的生成类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public final class SimpleServiceJavaDynamicProxy extends Proxy implements SimpleService &#123; private static Method m1; private static Method m2; private static Method m4; private static Method m3; private static Method m0; public SimpleServiceJavaDynamicProxy(InvocationHandler var1) throws &#123; super(var1); &#125; public final boolean equals(Object var1) throws &#123; try &#123; return ((Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;)).booleanValue(); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final void method2() throws &#123; try &#123; super.h.invoke(this, m4, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final void method1() throws &#123; try &#123; super.h.invoke(this, m3, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final int hashCode() throws &#123; try &#123; return ((Integer)super.h.invoke(this, m0, (Object[])null)).intValue(); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; static &#123; try &#123; m1 = Class.forName("java.lang.Object").getMethod("equals", new Class[]&#123;Class.forName("java.lang.Object")&#125;); m2 = Class.forName("java.lang.Object").getMethod("toString", new Class[0]); m4 = Class.forName("com.bobby.peng.learning.java.proxy.javadynamicproxy.SimpleService").getMethod("method2", new Class[0]); m3 = Class.forName("com.bobby.peng.learning.java.proxy.javadynamicproxy.SimpleService").getMethod("method1", new Class[0]); m0 = Class.forName("java.lang.Object").getMethod("hashCode", new Class[0]); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125;&#125; 由于动态代理的class继承了proxy，所以jdk动态代理必须要有接口。 super.h.invoke 其实调用的是InvocationHandler的方法，自己实现，一般是method.invoke(target,args)，所以在target内部调用，target.method1 直接调用 target.method2,调用栈在之前有显示，并不会经过proxy.method2,故@Transactional如果处于method2上会失效。 更加深入的了解一下jdk动态代理先看下newProxyInstance方法整个逻辑其实很简单，获得proxy的class，然后构造proxy实例。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; // 校验部分 Objects.requireNonNull(h); final Class&lt;?&gt;[] intfs = interfaces.clone(); final SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; checkProxyAccess(Reflection.getCallerClass(), loader, intfs); &#125; // 获取proxy的class（包括构造） /* * Look up or generate the designated proxy class. */ Class&lt;?&gt; cl = getProxyClass0(loader, intfs); /* * Invoke its constructor with the designated invocation handler. */ try &#123; if (sm != null) &#123; checkNewProxyPermission(Reflection.getCallerClass(), cl); &#125; // 构造对象 final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; if (!Modifier.isPublic(cl.getModifiers())) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;); &#125; return cons.newInstance(new Object[]&#123;h&#125;); &#125; catch (IllegalAccessException|InstantiationException e) &#123; throw new InternalError(e.toString(), e); &#125; catch (InvocationTargetException e) &#123; Throwable t = e.getCause(); if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new InternalError(t.toString(), t); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString(), e); &#125; &#125; 其中关键节点是getProxyClass0方法，下面是一整条调用链。通过接口可以发现，proxy class 仅仅与 classloader 和 interface 有关所以在继承InvocationHandler的时候，impl的实例是不存在的。仅仅只有proxy的实例。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114/* * Look up or generate the designated proxy class. */Class&lt;?&gt; cl = getProxyClass0(loader, intfs);/** * Generate a proxy class. Must call the checkProxyAccess method * to perform permission checks before calling this. */private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; if (interfaces.length &gt; 65535) &#123; throw new IllegalArgumentException("interface limit exceeded"); &#125; // If the proxy class defined by the given loader implementing // the given interfaces exists, this will simply return the cached copy; // otherwise, it will create the proxy class via the ProxyClassFactory return proxyClassCache.get(loader, interfaces);&#125;/** * Look-up the value through the cache. This always evaluates the * &#123;@code subKeyFactory&#125; function and optionally evaluates * &#123;@code valueFactory&#125; function if there is no entry in the cache for given * pair of (key, subKey) or the entry has already been cleared. * * @param key possibly null key * @param parameter parameter used together with key to create sub-key and * value (should not be null) * @return the cached value (never null) * @throws NullPointerException if &#123;@code parameter&#125; passed in or * &#123;@code sub-key&#125; calculated by * &#123;@code subKeyFactory&#125; or &#123;@code value&#125; * */// weak cache 源代码// 在proxy中 key : classloader ,parameter : interfacespublic V get(K key, P parameter) &#123; Objects.requireNonNull(parameter); // 清除已经被回收的weak reference map中的value值，在weak reference部分会有源码 expungeStaleEntries(); // 这里的cache key是一个weak reference 的 key // 关于weak reference 下文会有论述 // refQueue 的作用同样也在weak reference中阐述 Object cacheKey = CacheKey.valueOf(key, refQueue); // lazily install the 2nd level valuesMap for the particular cacheKey // map的第一层仅仅与classloader有关 // 我感觉这一层map的区分度不是很高，不如直接就采用一层map，直接用里面一层的，classloader和interface直接组成一个key // 外层是weak reference的key，意味着一旦被回收，该classloader所有的proxy就会被回收，感觉不太合理（todo 仔细想想） ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; valuesMap = map.get(cacheKey); if (valuesMap == null) &#123; ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; oldValuesMap = map.putIfAbsent(cacheKey, valuesMap = new ConcurrentHashMap&lt;&gt;()); // 参考 putIfAbsent 方法 return 说明 // return null的时候说明put的时候是absent的，如果不为null，说明有并发场景存在 // 外层判定是保证效率，内层判空是防止并发 if (oldValuesMap != null) &#123; valuesMap = oldValuesMap; &#125; &#125; // create subKey and retrieve the possible Supplier&lt;V&gt; stored by that // subKey from valuesMap // subKeyFactory.apply 构建的时候是通过parameter 也就是 接口来实现的 // key 也就是 classloader 并没有用到 // 也就是说 subkey 仅仅是接口相关而与实现类无关 Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter)); Supplier&lt;V&gt; supplier = valuesMap.get(subKey); Factory factory = null; while (true) &#123; if (supplier != null) &#123; // supplier might be a Factory or a CacheValue&lt;V&gt; instance // 下文会有分析 V value = supplier.get(); if (value != null) &#123; return value; &#125; &#125; // else no supplier in cache // or a supplier that returned null (could be a cleared CacheValue // or a Factory that wasn't successful in installing the CacheValue) // lazily construct a Factory if (factory == null) &#123; factory = new Factory(key, parameter, subKey, valuesMap); &#125; if (supplier == null) &#123; supplier = valuesMap.putIfAbsent(subKey, factory); if (supplier == null) &#123; // successfully installed Factory supplier = factory; &#125; // else retry with winning supplier &#125; else &#123; if (valuesMap.replace(subKey, supplier, factory)) &#123; // successfully replaced // cleared CacheEntry / unsuccessful Factory // with our Factory supplier = factory; &#125; else &#123; // retry with current supplier supplier = valuesMap.get(subKey); &#125; &#125; &#125; &#125; supplier might be a Factory or a CacheValue instance关于这句注释，当时看代码的时候有点奇怪，当时以为是简单的get，现在看来get都不是简单的get。 TAT Factory相关1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Overridepublic synchronized V get() &#123; // serialize access // re-check Supplier&lt;V&gt; supplier = valuesMap.get(subKey); if (supplier != this) &#123; // something changed while we were waiting: // might be that we were replaced by a CacheValue // or were removed because of failure -&gt; // return null to signal WeakCache.get() to retry // the loop // 防止多线程发生，因为在get外部不是同步的 return null; &#125; // else still us (supplier == this) // create new value V value = null; try &#123; // 这里的apply生成真正的proxy.class 文件 value = Objects.requireNonNull(valueFactory.apply(key, parameter)); &#125; finally &#123; if (value == null) &#123; // remove us on failure valuesMap.remove(subKey, this); &#125; &#125; // the only path to reach here is with non-null value assert value != null; // wrap value with CacheValue (WeakReference) // 构造valuemaps的新对象 CacheValue&lt;V&gt; cacheValue = new CacheValue&lt;&gt;(value); // try replacing us with CacheValue (this should always succeed) // replace牛逼啊！还是default的有木有啊！还是cas的卧槽！ if (valuesMap.replace(subKey, this, cacheValue)) &#123; // put also in reverseMap // reverse Map 感觉用Set会更好，因为塞入的值都是true // 而且只有在size和containsValue才有用 reverseMap.put(cacheValue, Boolean.TRUE); &#125; else &#123; throw new AssertionError("Should not reach here"); &#125; // successfully replaced us with new CacheValue -&gt; return the value // wrapped by it return value;&#125; 这里同步get的理由应该是要防止并发，并降低锁的粒度，否则锁的粒度应该构建整个map的时候就开始了。proxy生成的代码比较复杂就不看了 在构建类发现一行这个代码，也就是说只要将saveGeneratedFiles设为true就会生成proxy.class在硬盘上。 123456789101112131415161718192021222324private static final boolean saveGeneratedFiles = ((Boolean)AccessController.doPrivileged(new GetBooleanAction("sun.misc.ProxyGenerator.saveGeneratedFiles"))).booleanValue();if(saveGeneratedFiles) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; try &#123; int var1 = var0.lastIndexOf(46); Path var2; if(var1 &gt; 0) &#123; Path var3 = Paths.get(var0.substring(0, var1).replace('.', File.separatorChar), new String[0]); Files.createDirectories(var3, new FileAttribute[0]); var2 = var3.resolve(var0.substring(var1 + 1, var0.length()) + ".class"); &#125; else &#123; var2 = Paths.get(var0 + ".class", new String[0]); &#125; Files.write(var2, var4, new OpenOption[0]); return null; &#125; catch (IOException var4x) &#123; throw new InternalError("I/O exception saving generated file: " + var4x); &#125; &#125; &#125;);&#125; 默认在项目根目录下有个com.sun.xxx下就会出现proxy.class文件。不用单独的去写utils类了，以下是开启方法。1System.getProperties().put("sun.misc.ProxyGenerator.saveGeneratedFiles", "true"); 关于 weak reference 简单的理解 //todo 详细了解weak reference 对象被创建之后，如果没有任何引用指向他，且发生gc，则对象则会被消失。 如果引用的该对象的是一个集合，我们经常会在 代码中看到 node = null;//help gc 这样的代码来帮助gc。 但是cache是例外的，因为cache不知道他的生命周期是怎么样的，比如我们在使用redis的时候我们并不知道这个key应该存在多久，什么时候会被停止使用，是否够热。 那么cache的普通做法是lru或者lfu，来保证cache中的数据是最有效的。而内存中的cache一般不会那么做（redis有内存大小的限制），因为我们无法估算大小，且在系统允许的情况下存的越多越好。 而在上述proxy的使用场景下，一个interface下大概率也只用proxy.class一次（比如单例的service），而我们项目假设有1000个需要动态代理的class，那么在cache中的也有1000个对象，可能大部分是无效的，占用了大部分内存。 因为我们无法知晓cache的生命周期，所以 node = null; //help gc 这样的代码显然不适合我们。 所以weak reference的意义就在这里，当且仅当一个对象被weak reference指向时，gc时就被回收。 因为weak reference 是随着gc被回收，所以他的回收是具有不确定性的，一般用于易构建但是占用内存较大的对象。 代码中会看到清空ReferenceQueue，这里保存的是已经被回收的weak reference，因为weak reference本身是没有用的。 下面代码是关于weak reference的回收 123456789101112131415161718192021private void expungeStaleEntries() &#123; CacheKey&lt;K&gt; cacheKey; while ((cacheKey = (CacheKey&lt;K&gt;)refQueue.poll()) != null) &#123; //在weak reference的对象被回收之后，weak reference本身和map中的数据需要一并的清空 cacheKey.expungeFrom(map, reverseMap); &#125;&#125;void expungeFrom(ConcurrentMap&lt;?, ? extends ConcurrentMap&lt;?, ?&gt;&gt; map, ConcurrentMap&lt;?, Boolean&gt; reverseMap) &#123; // removing just by key is always safe here because after a CacheKey // is cleared and enqueue-ed it is only equal to itself // (see equals method)... ConcurrentMap&lt;?, ?&gt; valuesMap = map.remove(this); // remove also from reverseMap if needed if (valuesMap != null) &#123; for (Object cacheValue : valuesMap.values()) &#123; reverseMap.remove(cacheValue); &#125; &#125;&#125; cglib动态代理cglib调用栈以前虽然用的多但是从来没有思考过相关的实现（主要是懒）。图中红圈所示的两个地方是cglib两个不同的生成类。分别是enhanceClass 和 fastClass。 enhanceClass是调用了method1方法，可以认为是重写了父类接口。fastClass调用的是invoke接口反射到了目标类的method1，和之前jdk动态代理是一模一样的，所以一旦用fastClass进入了目标类的方法，@Transactional也依旧会失效。enhanceClass的理解大概和之前猜测的增强类实现应该一致，而fastClass是干嘛用的呢。 cglib demo代码12345678910111213141516171819202122232425262728293031public class SimpleCglibService &#123; public void method1() &#123; System.out.println("SimpleCglibService in method1"); method2(); &#125; public void method2() &#123; System.out.println("SimpleCglibService in method2"); &#125; public static void main(String[] args) &#123; System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, "/Users/peng2035/git/learning/learning-java/target/classes/com/bobby/peng/learning/java/proxy/cglib/"); Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(SimpleCglibService.class); enhancer.setCallback(new CglibProxy()); SimpleCglibService simpleCglibService = (SimpleCglibService) enhancer.create(); simpleCglibService.method1(); &#125;&#125;public class CglibProxy implements MethodInterceptor &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println("begin"); Object invoke = methodProxy.invoke(new SimpleCglibService(),objects); System.out.println("end"); return invoke; &#125;&#125; 其实代码和java动态代理差不多，就是InvocationHandler和cglib callback接口的差别还有构建的差别。分为以下几点 之前看到jdk动态代理的时候classloader是个绕不开的东西，invocationHandler创建的时候需要传入来做WeakCache的缓存的key，而enhancer只需要setCallback,new Enhancer中并没有要求传入classloader，代码里会自己去找上下文的ClassLoader。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// 和jdk动态代理的keyFactory类似public static KeyFactory create(Class keyInterface, KeyFactoryCustomizer first, List&lt;KeyFactoryCustomizer&gt; next) &#123; return create(keyInterface.getClassLoader(), keyInterface, first, next);&#125;public static KeyFactory create(ClassLoader loader, Class keyInterface, KeyFactoryCustomizer customizer, List&lt;KeyFactoryCustomizer&gt; next) &#123; Generator gen = new Generator(); gen.setInterface(keyInterface); if (customizer != null) &#123; gen.addCustomizer(customizer); &#125; if (next != null &amp;&amp; !next.isEmpty()) &#123; for (KeyFactoryCustomizer keyFactoryCustomizer : next) &#123; gen.addCustomizer(keyFactoryCustomizer); &#125; &#125; gen.setClassLoader(loader); return gen.create();&#125;protected Object create(Object key) &#123; try &#123; ClassLoader loader = getClassLoader(); Map&lt;ClassLoader, ClassLoaderData&gt; cache = CACHE; // 同样是通过classloader来进行一级缓存 ClassLoaderData data = cache.get(loader); if (data == null) &#123; // jdk动态代理1.8的情况下用putIfAbsent来解决了并发的效率问题 // cglib更加直观直接用同步锁来解决 synchronized (AbstractClassGenerator.class) &#123; cache = CACHE; data = cache.get(loader); if (data == null) &#123; Map&lt;ClassLoader, ClassLoaderData&gt; newCache = new WeakHashMap&lt;ClassLoader, ClassLoaderData&gt;(cache); data = new ClassLoaderData(loader); newCache.put(loader, data); CACHE = newCache; &#125; &#125; &#125; this.key = key; Object obj = data.get(this, getUseCache()); if (obj instanceof Class) &#123; return firstInstance((Class) obj); &#125; return nextInstance(obj); &#125; catch (RuntimeException e) &#123; throw e; &#125; catch (Error e) &#123; throw e; &#125; catch (Exception e) &#123; throw new CodeGenerationException(e); &#125; &#125; cglib intercept 方法中参数多了一个methodProxy 如果在代码中把interceptor的methodPrxoy替换成method，和jdk动态代理没有区别，代码调用栈如下1Object invoke = method.invoke(new SimpleCglibService(),objects); cglib的method proxy 中有两个方法，invoke 和 invokeSuper123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * Invoke the original method, on a different object of the same type. * @param obj the compatible object; recursion will result if you use the object passed as the first * argument to the MethodInterceptor (usually not what you want) * @param args the arguments passed to the intercepted method; you may substitute a different * argument array as long as the types are compatible * @see MethodInterceptor#intercept * @throws Throwable the bare exceptions thrown by the called method are passed through * without wrapping in an &lt;code&gt;InvocationTargetException&lt;/code&gt; */ public Object invoke(Object obj, Object[] args) throws Throwable &#123; try &#123; init(); FastClassInfo fci = fastClassInfo; //代码差异点 return fci.f1.invoke(fci.i1, obj, args); &#125; catch (InvocationTargetException e) &#123; throw e.getTargetException(); &#125; catch (IllegalArgumentException e) &#123; if (fastClassInfo.i1 &lt; 0) throw new IllegalArgumentException("Protected method: " + sig1); throw e; &#125; &#125; /** * Invoke the original (super) method on the specified object. * @param obj the enhanced object, must be the object passed as the first * argument to the MethodInterceptor * @param args the arguments passed to the intercepted method; you may substitute a different * argument array as long as the types are compatible * @see MethodInterceptor#intercept * @throws Throwable the bare exceptions thrown by the called method are passed through * without wrapping in an &lt;code&gt;InvocationTargetException&lt;/code&gt; */ public Object invokeSuper(Object obj, Object[] args) throws Throwable &#123; try &#123; init(); FastClassInfo fci = fastClassInfo; //代码差异点 return fci.f2.invoke(fci.i2, obj, args); &#125; catch (InvocationTargetException e) &#123; throw e.getTargetException(); &#125; &#125; 代码差异主要在fci.f1 fci.f2，这两个是不同的两个fastClassInfo。f1主要是原始类的子类很好理解f2则是一个fastClass 1234567891011121314151617181920212223242526272829public Object invoke(int var1, Object var2, Object[] var3) throws InvocationTargetException &#123; //原始类 SimpleCglibService var10000 = (SimpleCglibService)var2; int var10001 = var1; try &#123; switch(var10001) &#123; case 0: SimpleCglibService.main((String[])var3[0]); return null; case 1: var10000.method1(); return null; case 2: var10000.method2(); return null; case 3: return new Boolean(var10000.equals(var3[0])); case 4: return var10000.toString(); case 5: return new Integer(var10000.hashCode()); &#125; &#125; catch (Throwable var4) &#123; throw new InvocationTargetException(var4); &#125; throw new IllegalArgumentException("Cannot find matching method/constructor"); &#125; 逻辑其实很简单，通过index来确定调用哪个方法。 关于fastclassJdk动态代理的拦截对象是通过反射的机制来调用被拦截方法的，反射的效率比较低，所以cglib采用了FastClass的机制来实现对被拦截方法的调用。FastClass机制就是对一个类的方法建立索引，通过索引来直接调用相应的方法。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>复习</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例的N种写法]]></title>
    <url>%2F2017%2F12%2F18%2F%E5%8D%95%E4%BE%8B%E7%9A%84N%E7%A7%8D%E5%86%99%E6%B3%95%2F</url>
    <content type="text"><![CDATA[123456789101112public class Singleton1 &#123; private static Singleton1 singleton = null; private Singleton1() &#123;&#125; public static Singleton1 newInstance() &#123; if(singleton == null) &#123; singleton = new Singleton1(); &#125; return singleton; &#125;&#125; 优点：惰性加载缺点：多线程有问题 123456789101112public class Singleton2 &#123; private static Singleton2 singleton = null; private Singleton2() &#123;&#125; public synchonized static Singleton2 newInstance() &#123; if(singleton == null) &#123; return new Singleton2(); &#125; return singleton; &#125;&#125; 优点：多线程问题解决缺点：newInstance 阻塞 12345678910111213141516public class Singleton3 &#123; private static Singleton3 singleton = null; privte Singleton3() &#123;&#125; public static Singleton3 newInstance() &#123; if(singleton == null) &#123; synchonized(this.class) &#123; if(singleton == null) &#123; return new Singleton3(); &#125; &#125; &#125; return singleton; &#125;&#125; 优点：性能提升，不会再newInstance阻塞。缺点：线程安全有问题，new Singleton3()在指令重排序的情况下，可能只生成了半个对象。详解 12345678910111213141516public class Singleton4 &#123; private static volatile Singleton4 singleton = null; private Singleton4() &#123;&#125; public Singleton4 newInstance() &#123; if(singleton == null) &#123; sychonized(this.class) &#123; if(singleton == null) &#123; return new Singleton4(); &#125; &#125; &#125; return singleton; &#125;&#125; 优点：线程安全解决，性能可行，推荐缺点：写起来麻烦。 123456789public class Singleton5 &#123; private static Singleton5 singleton = new Singleton5(); private Singleton5() &#123;&#125; public static newInstance() &#123; return singleton; &#125;&#125; 优点：写起来简单，线程安全（classload）机制保证。缺点：在Singleton5被加载时 实例就已经被初始化了。1234private static Singleton5 singleton = null;static &#123; singleton = new Singleton5();&#125; 同理 123public enum Singleton6 &#123; SINGLETON;&#125; 优点：写法简单清晰，线程安全，effective java隆重推荐，不会因为序列化和反序列话新增对象缺点：不能实现懒加载 12345678910111213public class Singleton7 &#123; private static class SingletonHolder() &#123; private static final Singleton7 singleton = new Singleton7(); private SingletonHolder() &#123;&#125; &#125; private Singleton7() &#123;&#125; public Singleton7 newInstance() &#123; return SingletonHolder.singleton; &#125;&#125; 优点：间接实现了懒加载，因为在singleton加载的时候，SingletonHolder并不会被实例化。 实现方式 关键点 资源浪费 线程安全 多线程环境的性能足够优化 基础饱汉 懒加载 否 否 - 饱汉变种1 懒加载、同步 否 是 否 饱汉变种2 懒加载、DCL 否 否 - 饱汉变种3 懒加载、DCL、volatile 否 是 是 饿汉 静态变量初始化 是 是 是 Holder 静态变量初始化、holder 否 是 是 枚举 枚举本质、静态变量初始化 否 是 是 参考单例模式有几种写法 如果单例由不同的类装载器装入，那便有可能存在多个单例类的实例。假定不是远端存取，例如一些servlet容器对每个servlet使用完全不同的类装载器，这样的话如果有两个servlet访问一个单例类，它们就都会有各自的实例。 123456789private static Class getClass(String classname) throws ClassNotFoundException &#123; ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); if(classLoader == null) classLoader = Singleton.class.getClassLoader(); return (classLoader.loadClass(classname)); &#125; &#125; 如果Singleton实现了java.io.Serializable接口，那么这个类的实例就可能被序列化和复原。不管怎样，如果你序列化一个单例类的对象，接下来复原多个那个对象，那你就会有多个单例类的实例。 12345678910public class Singleton implements java.io.Serializable &#123; public static Singleton INSTANCE = new Singleton(); protected Singleton() &#123; &#125; private Object readResolve() &#123; return INSTANCE; &#125; &#125;]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>复习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL一些使用技巧与总结]]></title>
    <url>%2F2017%2F09%2F20%2FSQL%E4%B8%80%E4%BA%9B%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%E4%B8%8E%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[数据类型 更小的通常更好。 更小的数据类型通常更快，因为他们占用更少的磁盘，内存和CPU缓存，并且处理时需要的CPU周期也更少。 确保没有低估需要存储的值的范围，因为在schema中的多个地方增加数据类型的范围是一个非常耗时和痛苦的操作。 例：类似status字段就可以使用 tinyint unsigned，id 字段可以使用 bigint unsigned 选择更加合适的数据类型 不同的数据类型可能会在使用时引起歧义（例：时间可以用bigint，可以用datetime，可以用字符串，但是使用datetime不会引起歧义）。 字符串在排序规则和字符集上比整型时间等更加复杂。 char与varchar varchar是变长的数据类型，仅使用必要的数据空间，同时需要额外的空间存储长度。在数据产生变更时，容易产生页分裂。 varchar不预先分配存储空间，长度不要超过 5000，如果存储长 度大于此值，定义字段类型为 text，独立出来一张表，用主键来对应，避免影响其它字段索引效率 char是定长的数据类型，占用的空间会更大，但是不易产生碎片。会截取字符串最后的空格。 char适合存储非常短的字符串，或者长度几乎一致的字符串（md5）。而varchar则能满足大部分的要求。 引申：那么varchar(200)和varchar(5)区别在哪呢~ varchar在硬盘中是变长，而读取到内存则是定长，临时表同理，200的长度无疑更消耗性能。 索引 最左匹配原则，mysql会一直向右匹配直到遇到范围查询（&gt;,&lt;,between,like）就停止匹配。 例：a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整 线上遇到过同时建立(a,b,c)和（a,b）索引的，根据最左匹配原则，(a,b,c)已经能满足（a,b）的查询需求，所以(a,b)是有些多余的。如果之前是(a,b)的索引，仅需扩充成(a,b,c)即可，不需要新建索引。 范围查找的字段尽量放在索引的最后，详见第一条，c放在最后可以被有效的利用到，且不会阻塞被精确匹配的列。 严禁左模糊或者全模糊 = 和 in 可以乱序。 a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。 尽可能的选择区分度高的列作为索引。 区分度越高，扫描的记录越少，原理见B-Tree 区分度公式：count(distinct col)/count(*)详见下文 越接近1区分度越高。尽量高于0.1。 关于status 如果查询的频度很高，建议将status这类的枚举字段作为前缀。即使查询用不到，可以穷举，类似status in (1,2,3,4) &amp; a = 1 &amp; b = 2，上述前提是status覆盖度很高，且查询量很大，如果status大部分时候仅作为状态记录，则不建议用此方式。 索引列不能参与计算 比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’) 业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引。 唯一索引的查找效率非常高，且能防止脏数据的产生。 超过三个表禁止 join。需要 join 的字段，数据类型必须绝对一致;多表关联查询 时，保证被关联的字段需要有索引。 即使双表 join 也要注意表索引、SQL 性能。 在 varchar 字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据 实际文本区分度决定索引长度即可。 索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20 的索引，区分度会高达90%以上。 就是再加一列，作为Varchar的指纹列，可以用hash或者MD5，然后在指纹列上加索引，查询的时候可以用 where hash = ? and string = ?，同样可以适用于text。（针对前N个字段区分度不是很高的列可以使用这种方式，但是有一定的侵入性） 如果有 order by 的场景，请注意利用索引的有序性。order by 最后的字段是组合 索引的一部分，并且放在索引组合顺序的最后，避免出现 file_sort 的情况，影响查询性能。 正例：where a=? and b=? order by c; 索引:a_b_c 反例：索引中有范围查找，那么索引有序性无法利用，如:WHERE a&gt;10 ORDER BY b; 索引 a_b 无法排序。 利用覆盖索引来进行查询操作，避免回表。 覆盖索引（covering index）指一个查询语句的执行只需要从辅助索引中就可以得到查询记录，而不需要查询聚集索引中的记录。也可以称之为实现了索引覆盖。 聚簇索引 的数据是放置在叶子节点的，如果要走到叶子节点还需要硬盘的io操作，效率低。 说明 如果一本书需要知道第 11 章是什么标题，会翻开第 11 章对应的那一页吗?目录浏览一下就好，这个目录就是起到覆盖索引的作用。 利用延迟关联或者子查询优化超多分页场景。 MySQL 并不是跳过 offset 行，而是取 offset+N 行，然后返回放弃前 offset 行，返回 N 行，那当 offset 特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过 特定阈值的页数进行 SQL 改写。 优化方案：SELECT a.* FROM 表 1 a, (select id from 表 1 where 条件 LIMIT 100000,20 ) b where a.id=b.id 最好给分页加个限制，例如超过500页就不能查询了，数据量大的话建议走搜索引擎。 sql相关 不要使用 count(列名)或 count(常量)来替代 count(*)，count(*)是 SQL92 定义的 标准统计行数的语法，跟数据库无关，跟 NULL 和非 NULL 无关。 count(*)会统计值为 NULL 的行，而 count(列名)不会统计此列为 NULL 值的行。 count(distinct col) 计算该列除 NULL 之外的不重复行数，注意 count(distinct col1, col2) 如果其中一列全为NULL，那么即使另一列有不同的值，也返回为0。 当某一列的值全是 NULL 时，count(col)的返回结果为 0，但 sum(col)的返回结果为 NULL，因此使用 sum()时需注意 NPE 问题。 可以使用如下方式来避免sum的NPE问题:SELECT IF(ISNULL(SUM(g)),0,SUM(g)) FROM table; 感谢文兵大哥的意见参考阿里巴巴开发手册，高性能mysql]]></content>
      <categories>
        <category>tips</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[in ximalaya]]></title>
    <url>%2F2017%2F07%2F09%2Fin-ximalaya%2F</url>
    <content type="text"><![CDATA[感谢 感谢曾经帮助过我的喜马拉雅的小伙伴们。 感谢ted &amp; mandy领进门，两位的面试至今难忘，也促使我去学习了很多知识，非常感谢两位大神。 感谢rudy &amp; changming，虽然理念上可能是背道而驰，很多事情的处理上也不能苟同，但是还是指导我入门了分布式系统，DDD。 感谢曾大神 &amp; riven &amp; 峰哥，刚入职的好伙伴，感谢各位在业务和技术上方方面面的帮助，祝曾大神有越来越多的小姐姐，riven和峰哥更上一层楼吧~ 感谢单大，zhiting，我知道我的bug还是挺多的，业务感谢还是很不熟的TAT，感谢两位的包容&amp;cola，祝两位节节高升，嘻嘻。 感谢磊大，磊大的工作总是那么的block，给我上班时间学习提供了可能。祝磊大有一个能为其安排工作的后端码农~ 感谢金大，犹记得那次接口参数改了在hudson上导致的坑爹问题，感谢金大的包容，金大腿长1米8。 感谢兵大，每次和兵大对话感觉智商都被碾压，兵大都技术的理解和思考都非常深入，道标型人物~ 感谢yuanwhy &amp; 琛总，基础服务组的两位大哥，组内栋梁，交流的也比较多，两位高升之后也请带上小弟~ 感谢big ben，让我知道如何用手机逛gitlab，然后让我去修一下bug。 感谢rick，fred，鸿贵，陈杨，小宇，dylan 还有很多很多，感谢大家的帮助和支持。 感谢sunsun，至于为什么要谢，我完全不知道，巴特感觉还是要谢一下，巴结一下支付宝的总没错。（听说感谢一下会送我一个蚂蚁宝宝） 未来从xima离职两个月了，感觉自己颓废了很多，感觉要被兵哥 金大 yuanwhy &amp; 琛总这些曾经的小伙伴远远的甩在后面了，期间也看了不少理论性的闲书，感觉是时候动一动手，整理一下，重新做一些有趣的东西了。 作为一个全组最菜的咸鱼也是有梦想的~ finallyAugust is coming ! welcome to hz ! ToB is the best~]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>ximalaya</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mvcc-可见性源代码]]></title>
    <url>%2F2017%2F04%2F11%2Fmvcc-%E5%8F%AF%E8%A7%81%E6%80%A7%E6%BA%90%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485class MVCC;/** Read view lists the trx ids of those transactions for which a consistentread should not see the modifications to the database. */...class ReadView &#123; ... private: // Prevent copying ids_t(const ids_t&amp;); ids_t&amp; operator=(const ids_t&amp;); private: /** Memory for the array */ value_type* m_ptr; /** Number of active elements in the array */ ulint m_size; /** Size of m_ptr in elements */ ulint m_reserved; friend class ReadView; &#125;;public: ReadView(); ~ReadView(); /** Check whether transaction id is valid. @param[in] id transaction id to check @param[in] name table name */ static void check_trx_id_sanity( trx_id_t id, const table_name_t&amp; name);// 判断一个修改是否可见 /** Check whether the changes by id are visible. @param[in] id transaction id to check against the view @param[in] name table name @return whether the view sees the modifications of id. */ bool changes_visible( trx_id_t id, const table_name_t&amp; name) const MY_ATTRIBUTE((warn_unused_result)) &#123; ut_ad(id &gt; 0); if (id &lt; m_up_limit_id || id == m_creator_trx_id) &#123; return(true); &#125; check_trx_id_sanity(id, name); if (id &gt;= m_low_limit_id) &#123; return(false); &#125; else if (m_ids.empty()) &#123; return(true); &#125; const ids_t::value_type* p = m_ids.data(); return(!std::binary_search(p, p + m_ids.size(), id)); &#125;private: // Disable copying ReadView(const ReadView&amp;); ReadView&amp; operator=(const ReadView&amp;);private: // 活动事务中的id的最大 /** The read should not see any transaction with trx id &gt;= this value. In other words, this is the "high water mark". */ trx_id_t m_low_limit_id; // 活动事务id的最小值 /** The read should see all trx ids which are strictly smaller (&lt;) than this value. In other words, this is the low water mark". */ // trx_id_t m_up_limit_id; /** trx id of creating transaction, set to TRX_ID_MAX for free views. */ trx_id_t m_creator_trx_id; /** Set of RW transactions that was active when this snapshot was taken */ ids_t m_ids; /** The view does not need to see the undo logs for transactions whose transaction number is strictly smaller (&lt;) than this value: they can be removed in purge if not needed by other views */ trx_id_t m_low_limit_no; /** AC-NL-RO transaction view that has been "closed". */ bool m_closed; typedef UT_LIST_NODE_T(ReadView) node_t; /** List of read views in trx_sys */ byte pad1[64 - sizeof(node_t)]; node_t m_view_list;&#125;;]]></content>
      <categories>
        <category>tips</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发Queue]]></title>
    <url>%2F2017%2F03%2F31%2F%E5%B9%B6%E5%8F%91Queue%2F</url>
    <content type="text"><![CDATA[BlockQueue 四种形式 抛出异常 返回一个特殊值(可能是null或者是false，取决于具体的操作) 阻塞当前执行直到其可以继续 当线程被挂起后，等待最大的时间，如果一旦超时，即使该操作依旧无法继续执行，线程也不会再继续等待下去。 注意： BlockingQueue中是不允许添加null的，该接受在声明的时候就要求所有的实现类在接收到一个null的时候，都应该抛出NullPointerException。(poll在没有数据的时候会返回null)。 123456789 public E poll() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; return (count == 0) ? null : dequeue();//当count==0时，返回null &#125; finally &#123; lock.unlock(); &#125;&#125; BlockingQueue是线程安全的，因此它的所有和队列相关的方法都具有原子性。但是对于那么从Collection接口中继承而来的批量操作方法，比如addAll(Collection e)等方法，BlockingQueue的实现通常没有保证其具有原子性，因此我们在使用的BlockingQueue，应该尽可能地不去使用这些方法。 BlockingQueue主要应用于生产者与消费者的模型中，其元素的添加和获取都是极具规律性的。但是对于remove(Object o)这样的方法，虽然BlockingQueue可以保证元素正确的删除，但是这样的操作会非常响应性能，因此我们在没有特殊的情况下，也应该避免使用这类方法。 ArrayBlockingQueue基于数组的并发阻塞队列 构造方法12345678public ArrayBlockingQueue(int capacity, boolean fair) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition();&#125; 由ReentrantLock实现，公正锁实现，为了保证List的先进先出。除了在内部array未满的时候需要满足先进先出，还需要保证await的线程在signal的时候保证是顺序的（todo condition 源码解析，大致理解是condition内部也是维护一个队列，在signal的时候唤醒的是firstWaiter，这样就能保证线程是顺序唤醒的）。 插入12345678910111213141516171819202122public void put(E e) throws InterruptedException &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == items.length) notFull.await(); enqueue(e); &#125; finally &#123; lock.unlock(); &#125;&#125;private void enqueue(E x) &#123; // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; items[putIndex] = x; if (++putIndex == items.length) putIndex = 0; count++; notEmpty.signal();//为了保证先进先出的效果，需要保证signal是顺序的&#125; 移除12345678910111213141516171819202122232425public E poll() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; return (count == 0) ? null : dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125;private E dequeue() &#123; // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; @SuppressWarnings(&quot;unchecked&quot;) E x = (E) items[takeIndex]; items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued();//删除迭代器中的数据 notFull.signal(); return x;&#125; DelayQueueDelayQueue主要用于放置实现了Delay接口的对象，其中的对象只能在其时刻到期时才能从队列中取走。这种队列是有序的，即队头的延迟到期时间最短。如果没有任何延迟到期，那么久不会有任何头元素。 重点 无界的BlockingQueue poll方法立即返回，如果没有头结点则返回null。take方法会阻塞直到有头结点才返回。代码分析 成员变量1234private final transient ReentrantLock lock = new ReentrantLock();private final PriorityQueue&lt;E&gt; q = new PriorityQueue&lt;E&gt;();private Thread leader = null;private final Condition available = lock.newCondition(); 内部由优先队列实现，available来控制他的阻塞和通知。lock，还有用于优化阻塞通知的线程元素leader。 offer(E e)1234567891011121314public boolean offer(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; q.offer(e); if (q.peek() == e) &#123; leader = null; available.signal(); &#125; return true; &#125; finally &#123; lock.unlock(); &#125;&#125; 在头元素为空的情况下，插入头元素将会唤醒线程。 take()123456789101112131415161718192021222324252627282930313233public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; E first = q.peek(); if (first == null) available.await();//队列中没有元素的时候，进入等待 else &#123; long delay = first.getDelay(NANOSECONDS); if (delay &lt;= 0) return q.poll(); first = null; // don&apos;t retain ref while waiting if (leader != null) available.await(); else &#123; Thread thisThread = Thread.currentThread(); leader = thisThread; //用于判断是否有线程在获取 try &#123; available.awaitNanos(delay); &#125; finally &#123; if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; if (leader == null &amp;&amp; q.peek() != null) available.signal(); lock.unlock(); &#125;&#125; 1first = null; // don&apos;t retain ref while waiting 想想假设现在延迟队列里面有三个对象。 线程A进来获取first,然后进入 else 的else ,设置了leader为当前线程A 线程B进来获取first,进入else的阻塞操作,然后无限期等待 如果线程A阻塞完毕,获取对象成功,出队,这个对象理应被GC回收,但是他还被线程B持有着,GC链可达,所以不能回收这个first. 假设还有线程C 、D、E.. 持有对象1引用,那么无限期的不能回收该对象1引用了,那么就会造成内存泄露. //todo 实现一个带超时的缓存，实现一下delayedQueue LinkedBlockingQueue适合实现一个消费者生产者队列 代码分析12345678910111213private final AtomicInteger count = new AtomicInteger();/** Lock held by take, poll, etc */private final ReentrantLock takeLock = new ReentrantLock();/** Wait queue for waiting takes */private final Condition notEmpty = takeLock.newCondition();/** Lock held by put, offer, etc */private final ReentrantLock putLock = new ReentrantLock();/** Wait queue for waiting puts */private final Condition notFull = putLock.newCondition(); 读写分离，take 和 put 不互斥。ArrayBlockingQueue 为什么只用了一把锁。猜想：ArrayBlockingQueue 是一个环形数组，如果用两把锁，对capacity的判断可能是失效，会导致put的时候插入了存在的数据。而LinkedBlockingQueue 是基于链表的，添加和删除的时候是对于head和last的操作，互不相关，所以可以用两把锁来实现。因为使用了两把锁，所以count使用了AtomicInteger来实现，保证其并发。 offer(E e) 12345678910111213141516171819202122232425262728public boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); final AtomicInteger count = this.count; if (count.get() == capacity) return false; // int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; putLock.lock(); try &#123; if (count.get() &lt; capacity) &#123; enqueue(node); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty(); return c &gt;= 0;&#125;private void enqueue(Node&lt;E&gt; node) &#123; // assert putLock.isHeldByCurrentThread(); // assert last.next == null; last = last.next = node;//last = head = new Node&lt;E&gt;(null); 初始化的时候head=last，所以在第一个节点插入的时候，head会被赋值&#125; poll 123456789101112131415161718192021222324252627282930313233public E poll() &#123; final AtomicInteger count = this.count; if (count.get() == 0) return null; E x = null; int c = -1; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try &#123; if (count.get() &gt; 0) &#123; x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); &#125; &#125; finally &#123; takeLock.unlock(); &#125; if (c == capacity) signalNotFull(); return x;&#125;private E dequeue() &#123; // assert takeLock.isHeldByCurrentThread(); // assert head.item == null; Node&lt;E&gt; h = head; Node&lt;E&gt; first = h.next; h.next = h; // help GC head = first; E x = first.item; first.item = null; return x;&#125; LinkedTransferQueue//todo PriorityBlockingQueue//todo SynchronousQueue//todo ConcurrentQueue//todo ConcurrentLinkedQueue//todo]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>复习</tag>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IO]]></title>
    <url>%2F2017%2F03%2F29%2FIO%2F</url>
    <content type="text"><![CDATA[基本概念用户空间和内核空间现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操作系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。 进程切换为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。详解 从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化： 保存处理机上下文，包括程序计数器和其他寄存器。 更新PCB信息。 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。 选择另一个进程执行，并更新其PCB。 更新内存管理的数据结构。 恢复处理机上下文。 进程阻塞正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。（所以太多的cas会损耗cpu的太多性能？todo） 文件描述符（File descriptor）文件描述符是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。 缓存IO缓存 IO 又被称作标准 IO，大多数文件系统的默认 IO 操作都是缓存 IO。在 Linux 的缓存 IO 机制中，操作系统会将 IO 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。缺点：数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 IO模型Linux内核将所有外部设备都看作一个文件来操作，对一个文件的读写会调用 内核 提供的系统命令，返回一个文件描述符(file descriptor)，对一个socket读写也有对应的描述符，叫做socketfd，描述符就是一个数字，指向内核中的一个结构体(内核为各个进程维护的打开文件的记录表) 一次IO操作会将数据先写入内核缓冲区 再将数据转移至进程缓冲区ex: 发生一次read操作后，会发生两件事 等待数据包到达就绪 数据被复制到应用进程的缓冲区 网络应用需要处理的无非就是两大类问题，网络IO，数据计算。相对于后者，网络IO的延迟，给应用带来的性能瓶颈大于后者。关于同步非同步 异步非异步的简单理解 同步模型阻塞IO(blocking io)在这个IO模型中，用户空间的应用程序执行一个系统调用（recvform），这会导致应用程序阻塞，什么也不干，直到数据准备好，并且将数据从内核复制到用户进程，最后进程再处理数据，在等待数据到处理数据的两个阶段，整个进程都被阻塞。不能处理别的网络IO。调用应用程序处于一种不再消费 CPU 而只是简单等待响应的状态，因此从处理的角度来看，这是非常有效的。在调用recv()/recvfrom()函数时，发生在内核中等待数据和复制数据的过程，大致如下图： 非阻塞IO(non-blocking io) 在网络IO时候，非阻塞IO会进行recvform系统调用，检查数据是否准备好，与阻塞IO不一样，可以重复调用recvfrom进行轮训。 优点：多个任务可以同时执行。 缺点：数据在轮训期间准备完毕，会拉长整个流程的时间，降低吞吐量。 多路复用IO(multiplexing io) IO多路复用有两个特别的系统调用select、poll、epoll（效率更高）函数。select调用是内核级别的，select轮询相对非阻塞的轮询的区别在于—前者可以等待多个socket，能实现同时对多个IO端口进行监听，当其中任何一个socket的数据准好了，就能返回进行可读，然后进程再进行recvform系统调用，将数据由内核拷贝到用户进程，当然这个过程是阻塞的。select或poll调用之后，会阻塞进程，与blocking IO阻塞不同在于， 此时的select不是等到socket数据全部到达再处理, 而是有了一部分数据就会调用用户进程来处理。（单任务全部完成之后才会复制到用户进程，可以同时对多个任务进行操作） I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这两个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时（注意不是全部数据可读或可写），才真正调用I/O操作函数。 对于多路复用，也就是轮询多个socket。多路复用既然可以处理多个IO，也就带来了新的问题，多个IO之间的顺序变得不确定了，当然也可以针对不同的编号。具体流程，如下图所示： IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 上面的图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。 所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。（select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。） 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。所以IO多路复用是阻塞在select，epoll这样的系统调用之上，而没有阻塞在真正的I/O系统调用如recvfrom之上。 在I/O编程过程中，当需要同时处理多个客户端接入请求时，可以利用多线程或者I/O多路复用技术进行处理。I/O多路复用技术通过把多个I/O的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。与传统的多线程/多进程模型比，I/O多路复用的最大优势是系统开销小，系统不需要创建新的额外进程或者线程，也不需要维护这些进程和线程的运行，降底了系统的维护工作量，节省了系统资源，I/O多路复用的主要应用场景如下： 详见 IO多路复用 详见 epoll 信号驱动式IO(signal-driven io)(同步？revfrom是用户进程调用) 首先我们允许Socket进行信号驱动IO,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。过程如下图所示： 异步模型异步非阻塞相对于同步IO，异步IO不是顺序执行。用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。IO两个阶段，进程都是非阻塞的。 Linux提供了AIO库函数实现异步，但是用的很少。目前有很多开源的异步IO库，例如libevent、libev、libuv。异步过程如下图所示： 用户进程发起aio_read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal或执行一个基于线程的回调函数来完成这次 IO 处理过程，告诉它read操作完成了。 异步阻塞 有时我们的 API 只提供异步通知方式，例如在 node.js 里，但业务逻辑需要的是做完一件事后做另一件事，例如数据库连接初始化后才能开始接受用户的 HTTP 请求。这样的业务逻辑就需要调用者是以阻塞方式来工作。为了在异步环境里模拟 “顺序执行” 的效果，就需要把同步代码转换成异步形式，这称为 CPS（Continuation Passing Style）变换。BYVoid 大神的 continuation.js 库就是一个 CPS 变换的工具。用户只需用比较符合人类常理的同步方式书写代码，CPS 变换器会把它转换成层层嵌套的异步回调形式。(callback的时候执行剩余逻辑？ 主线程卡死？ 使用回调来返回？) cps相关 另外一种使用阻塞方式的理由是降低响应延迟。如果采用非阻塞方式，一个任务 A 被提交到后台，就开始做另一件事 B，但 B 还没做完，A 就完成了，这时要想让 A 的完成事件被尽快处理（比如 A 是个紧急事务），要么丢弃做到一半的 B，要么保存 B 的中间状态并切换回 A，任务的切换是需要时间的（不管是从磁盘载入到内存，还是从内存载入到高速缓存），这势必降低 A 的响应速度。因此，对实时系统或者延迟敏感的事务，有时采用阻塞方式比非阻塞方式更好。 NIO 和 IO的区别区别 IO NIO Stream oriented Buffer oriented Blocking IO Non blocking IO Selectors 概念 IO 阻塞IO 标准IO是面向Stream的，每次从Stream中读取出字节，它不能在流中的数据前后移动，不能说已经读到后面了，再跳到前面去。 Stream是阻塞的，当一个线程调用read或write时，线程是阻塞的，只有等数据读取/写入完成，期间线程不能做任何事。 NIO 非阻塞IO NIO把数据读到一个待处理的Buffer中，也可以在buffer中来回移动，但是不保证Buffer中的数据是所需要的完整数据，需要去校验。 NIO使用一个线程从某个通道中读取数据，但是仅能从Buffer中获得当前的部分数据，而数据变为完整之前，线程并不会被阻塞，而是可以去做其他的事情。写入也是这样，不需要等待它完全写入，就可以去做其他的事情。这里的“其他事情”大部分也是指在其它通道上执行IO操作，所以一个线程可以管理多个输入/输出通道，Selector就是跑在这个线程。 好处：一个Selector能同时对多个Socket连接进行管理。而不会阻塞当前的Selector线程。如果是原有的IO模型，在一个read或者write出现网络问题的时候不能进行下一步的操作，要解决这个问题只能开辟新的线程。这样就会导致线程数太多。而线程池的方案也会有出现多个线程阻塞而拖慢整个系统的问题。类图 例子 1234Name: AnnaAge: 25Email: anna@mailserver.comPhone: 1234567890 IO 12345BufferedReader reader = new BufferedReader(new InputStreamReader(input));String nameLine = reader.readLine();String ageLine = reader.readLine();String emailLine = reader.readLine();String phoneLine = reader.readLine(); NIO 12345ByteBuffer buffer = ByteBuffer.allocate(48);int bytesRead = channel.read(buffer);while(! bufferFull(bytesRead) ) &#123; bytesRead = channel.read(buffer);&#125; 需要循环来读取buffer中的所有的值。 NIO实现相关NIO主要的组件有Channel、Buffer、Selector Channel和Buffer和Stream相比，你可以同时对一个Channel进行读和写操作，而Stream只能读或写。 Channel可以异步进行读写。 Channel只和Buffer进行交互。 Channel子类（todo 实现） FileChannel 只能阻塞 详细原因 DatagramChannel 通过UDP 向网络中读写数据 SocketChannel 通过TCP 向网络中读写数据 ServerSocketChannel 允许监听即将到来的TCP连接 12345678910111213141516171819RandomAccessFile aFile = new RandomAccessFile(&quot;data/nio-data.txt&quot;, &quot;rw&quot;); FileChannel channel = aFile.getChannel(); ByteBuffer buf = ByteBuffer.allocate(48); int bytesRead = channel.read(buf); while (bytesRead != -1) &#123; System.out.println(&quot;Read &quot; + bytesRead); buf.flip(); while(buf.hasRemaining())&#123; System.out.print((char) buf.get()); &#125; buf.clear(); bytesRead = channel.read(buf); &#125; aFile.close(); buffer ByteBuffer CharBuffer IntBuffer buffer 属性 position limit capacity 基本用法使用Buffer读写数据一般遵循以下四个步骤： 写入数据到Buffer 调用flip()方法 从Buffer中读取数据 调用clear()方法或者compact()方法 Buffer初始化时需要调用各个Buffer的allocate方法，比如CharBuffer cb = CharBuffer.allocate(48); //分配48个char大小的buffer 可以通过buffer.put(x)自己写入数据，也可以调用channel.read把channel中数据写入buffer 可以通过buffer.read()读出数据，也可以channel.write(buf)把buffer中的数据读出来 写入到Channel中 源码分析position和limit的意义在读模式和写模式下是不同的 Invariants: mark &lt;= position &lt;= limit &lt;= capacity（在切换模式和清空buffer的时候都需要重置mark标志位，保证上述关系） filp()flip方法将Buffer从写模式切换到读模式。调用flip()方法会将position设回0，并将limit设置成之前position的值。123456public final Buffer flip() &#123; limit = position; position = 0; mark = -1; return this;&#125; rewind()Buffer.rewind()将position设回0，所以你可以重读Buffer中的所有数据。limit保持不变，仍然表示能从Buffer中读取多少个元素（byte、char等）。 12345public final Buffer rewind() &#123; position = 0; mark = -1; return this;&#125; clear()与compact()方法一旦读完Buffer中的数据，需要让Buffer准备好再次被写入。可以通过clear()或compact()方法来完成。 如果调用的是clear()方法，position将被设回0，limit被设置成 capacity的值。换句话说，Buffer 被清空了。Buffer中的数据并未清除，只是这些标记告诉我们可以从哪里开始往Buffer里写数据。 如果Buffer中有一些未读的数据，调用clear()方法，数据将“被遗忘”，意味着不再有任何标记会告诉你哪些数据被读过，哪些还没有。 123456public final Buffer clear() &#123; position = 0; limit = capacity; mark = -1; return this;&#125; 如果Buffer中仍有未读的数据，且后续还需要这些数据，但是此时想要先先写些数据，那么使用compact()方法。 compact()方法将所有未读的数据拷贝到Buffer起始处。然后将position设到最后一个未读元素正后面。limit属性依然像clear()方法一样，设置成capacity。现在Buffer准备好写数据了，但是不会覆盖未读的数据。（Buffer类中不存在，但是在ByteBuffer中有个抽象方法） 选取DirectByteBuffer实现123456789101112public ByteBuffer compact() &#123; int pos = position(); int lim = limit(); assert (pos &lt;= lim); int rem = (pos &lt;= lim ? lim - pos : 0); unsafe.copyMemory(ix(pos), ix(0), (long)rem &lt;&lt; 0); position(rem); limit(capacity()); discardMark(); return this;&#125; mark()与reset()方法通过调用Buffer.mark()方法，可以标记Buffer中的一个特定position。之后可以通过调用Buffer.reset()方法恢复到这个position。例如： 123456789101112public final Buffer mark() &#123; mark = position; return this;&#125;public final Buffer reset() &#123; int m = mark; if (m &lt; 0) throw new InvalidMarkException(); position = m; return this;&#125; Scatter/Gather基本概念 分散（scatter）从Channel中读取是指在读操作时将读取的数据写入多个buffer中。因此，Channel将从Channel中读取的数据“分散（scatter）”到多个Buffer中。1234ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);ByteBuffer[] byteArray = &#123;header, body&#125;;channel.read(byteArray); 注意buffer首先被插入到数组，然后再将数组作为channel.read() 的输入参数。read()方法按照buffer在数组中的顺序将从channel中读取的数据写入到buffer，当一个buffer被写满后，channel紧接着向另一个buffer中写。 Scattering Reads在移动下一个buffer前，必须填满当前的buffer，这也意味着它不适用于动态消息(消息大小不固定)。换句话说，如果存在消息头和消息体，消息头必须完成填充（例如 128byte），Scattering Reads才能正常工作。 聚集（gather）写入Channel是指在写操作时将多个buffer的数据写入同一个Channel，因此，Channel 将多个Buffer中的数据“聚集（gather）”后发送到Channel。1234ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);ByteBuffer[] byteArray = &#123;header, body&#125;;channel.write(byteArray); buffers数组是write()方法的入参，write()方法会按照buffer在数组中的顺序，将数据写入到channel，注意只有position和limit之间的数据才会被写入。因此，如果一个buffer的容量为128byte，但是仅仅包含58byte的数据，那么这58byte的数据将被写入到channel中。因此与Scattering Reads相反，Gathering Writes能较好的处理动态消息。 Selector基本概念 一个线程来操作多个channel，减少上下文开销。Selector的创建1Selector selector = Selector.open(); 向Selector注册通道为了将Channel和Selector配合使用，必须将channel注册到selector上。通过SelectableChannel.register()方法来实现，如下：12channel.configureBlocking(false);SelectionKey key = channel.register(selector,Selectionkey.OP_READ); 与Selector一起使用时，Channel必须处于非阻塞模式下。这意味着不能将FileChannel（上文有讲）与Selector一起使用，因为FileChannel不能切换到非阻塞模式。而套接字通道都可以。 事件类型有Connect、Accept、Read、Write，都是说这个事件已经ready的时候才触发。如果不止对一种事件感兴趣，可以用“位或”操作符将常量连接起来.1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; SelectionKeyinterest集合1234public static final int OP_READ = 1;public static final int OP_WRITE = 4;public static final int OP_CONNECT = 8;public static final int OP_ACCEPT = 16; 与操作就能判断监听了什么事件类型。 ready集合判断哪些事件已经完成12345int readySet = selectionKey.readyOps();selectionKey.isAcceptable();selectionKey.isConnectable();selectionKey.isReadable();selectionKey.isWritable(); selector + channel12Channel channel = selectionKey.channel();Selector selector = selectionKey.selector(); attachment(附加对象)可以在注册时附加对象，在selectionKey中获取对象1234selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment();SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject); 例子12345678910111213141516171819202122Selector selector = Selector.open();channel.configureBlocking(false);SelectionKey key = channel.register(selector, SelectionKey.OP_READ);while(true) &#123; int readyChannels = selector.select(); if(readyChannels == 0) continue; Set selectedKeys = selector.selectedKeys(); Iterator keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if(key.isAcceptable()) &#123; // a connection was accepted by a ServerSocketChannel. &#125; else if (key.isConnectable()) &#123; // a connection was established with a remote server. &#125; else if (key.isReadable()) &#123; // a channel is ready for reading &#125; else if (key.isWritable()) &#123; // a channel is ready for writing &#125; keyIterator.remove(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839Set&lt;SelectionKey&gt; selectKeys = selector.selectedKeys();Selector selector = Selector.open();channel.configureBlocking(false);SelectionKey key = channel.register(selector, SelectionKey.OP_READ);while(true) &#123;int readyChannels = selector.select();if(readyChannels == 0) continue;Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys();Iterator&lt;SelectionKey&gt; keyIterator = selectedKeys.iterator();while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if(key.isAcceptable()) &#123; // a connection was accepted by a ServerSocketChannel. &#125; else if (key.isConnectable()) &#123; // a connection was established with a remote server. &#125; else if (key.isReadable()) &#123; // a channel is ready for reading &#125; else if (key.isWritable()) &#123; // a channel is ready for writing &#125; keyIterator.remove();&#125;&#125; nio相关服务端客户端代码 Java I/O模型的演进BIO通信模型当新建一个Socket连接时，由于读/写都是阻塞的，那么就需要一条线程来完成读写操作，即一条线程对应一个Socket连接，如果Socket连接数过多时，线程数过多会导致系统性能下降，栈溢出、创建新线程失败等问题。尝试使用线程池来控制线程资源的数量的方法，但是底层本质上还是阻塞通信，Socket读写在操作完全完成之前，线程会阻塞在I/O操作上，如果 对方发送请求 或者 应答消息 缓慢，或者 网络传输较慢，读写操作所在的线程就会长时间被阻塞，在此期间，其它线程只能在消息队列中排队。比如OutputStream的write操作，线程会被阻塞直到 所有要发送的字节 全部写入完毕，在TCP中，当消息方接受缓慢的时候，不能及时从TCP缓冲区中读出数据，那么发送端就会调整减小window size，写入速度也会越来越慢，此时使用的是阻塞IO，线程就会被阻塞很长时间，如果线程池中所有的线程都被长时间阻塞了，新来的任务就会排队进入任务队列，而任务队列满了之后，再继续提交任务就会导致提交任务的线程阻塞，新的请求会被拒绝，客户端大量超时。（所以适合的超时机制很重要。） 我们无法保证 生产环境的网络状况，对方应用处理速度，如果我们的系统依赖于对方的处理速度，可靠性就无法保证。 NIO通信模型在面向Stream的IO中数据直接写入或读到Steram中，而NIO中，引入了Buffer缓冲区的概念，让Buffer和Channel进行交互。SocketChannel和ServerSocketChannel可以被设置为unblocking的模式，connect/read/write操作不会阻塞当前线程，这样使用selector一个线程管理多个网络IO操作成为可能。Java的NIO使用epoll实现，性能也不会随着客户端增加而下降。 Java 传统IO主要包括字节流和字符流两种Java NIO 和 Netty作为一个NIO服务端，需要能够处理 网络的闪断、客户端的重复接入、客户端的安全认证、消息编解码、半包读写等情况，难度是比较大的。1.Java NIO的API使用起来比较复杂，而netty的api简单，大部分只用关注业务逻辑，灵活扩展。2.必须对多线程和网络编程非常熟悉，才能写出高质量的NIO程序。3.实现上述的诸多功能工作量和难度较大，而netty做好了封装也很成熟 java iojava io操作类包含在java.io包下，将近80个类，大概分为4组：1.基于字节操作的I/O接口，如InputStream、OutputStream2.基于字符操作的I/O接口，如Reader、Write3.基于磁盘操作的I/O接口，File4.基于网络操作的I/O接口，如Socket前两种是根据传输数据的格式(字节流/字符流)，后两种是传输数据的方式(磁盘/网络) Java 传统IO主要包括字节流和字符流两种 ByteArrayInputStream 12345ByteArrayInputStream &#123; byte[] buf; //inputStream的内容 int pos; //当前读到的位置 int mark; //调用mark标记当前pos，调用reset后可以把pos置回标记的mark处&#125; FileInputStream 对文件的读取，其中大部分的实现调用native完成 FilterInputStream 本身只是把请求委派给内部的InputStream，做一个Decorator，其子类做了各种包装 BufferedInputStream 把内部包装的InputStream读取一些存在一个byte[] buf中，读的时候可以直接中自己的buf中读 DataInputStream 可以读取若干个字节，转换成int、byte、short、UTF字符等类型返回 ObjectInputStream把字节流反序列化为对象，包装内部的一个DataInputStream的数据源，也是一个DecoratorIO流详解]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>复习</tag>
        <tag>io</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[wow的岁月]]></title>
    <url>%2F2017%2F03%2F28%2Fwow%E7%9A%84%E5%B2%81%E6%9C%88%2F</url>
    <content type="text"><![CDATA[离开艾泽拉斯很久了，暂时也不能回归，写个文章纪念一下在艾泽拉斯奋战的岁月起 因为wow的第一部CG入坑，直到今天看来，这部CG依旧完爆大部分游戏的CG，当时年幼的我被深深的矮人猎开出的第一枪深深地震撼到了，随即入坑，选择了一个人类女法师，在艾尔文森林愉快地搓起了寒冰箭。 从被霍格追杀，死亡矿井迷路，血色被狗男女灭的死去活来，为了收集荆棘谷的青山在综合频道喊话，东瘟疫之地的爱与家庭，到ZUG,MC,BWL。见到了AL之后再无兄弟，还有象征着主T的荣耀的雷霆之怒，逐风者祝福之剑。 随后跟着朋友在战歌，阿拉希，和奥山疯狂刷荣誉。依稀记得1234冲石炉，56男人，78急救。看着别人穿着一身金光闪闪的大元帅战士羡慕不已。 燃烧的远征开启，穿过黑暗之门来到外域，见到了纳格兰的美丽风景，为了哈兰羊到处刷念珠。永远卡成狗的沙塔斯城。还有屁大点事就能引起团战的奎岛。 现在想来，甚至有点怀念曾经不组队杀不了精英的日子，联盟部落见面就开战，荆棘谷，南海镇，LM,BL野战各种high。 承 因为学习慢慢的远离了wow，错过了WLK还有CTM两个大版本。也是错过了wow最巅峰的时期。在熊猫人之谜前夕受室友感召回归，发现艾泽拉斯的大地已经发生了翻天覆地的变化，转而玩了WLK之前都没有的英雄职业兽人dk（结果发现是个杯具）。 最开始学校网络非常不稳定，只能在杜隆塔尔门口决斗，被战猎焦作人，天神鲁莽震荡波，红人动物园准备就绪再来一套。最初大概只有100胜300负的胜率。随着战猎被砍，跨服决斗的开启，决斗套路越来越熟悉，大概最后到了7500胜1500负的战绩。 在奥尔加隆门口决斗的时候遇见了法师队友阿黄，一个除了吹比啥都不会的亡灵女法师。奶骑“大神”-wcz。还有一个法师转战士的亡者断魂。慢慢的进入了竞技场和评级战场。 评级战场：一个惩戒骑团长带我和麻子的法师遨游1600，随后进入了当时非常仰慕的太极龙带队的评级团，4战2dk最后大概定格在2800左右的评级吧。 竞技场：和wcz，亡者断魂，三板一个下午2199，最后因为战士掉线三把，回到2000，因为排不到队伍，也没有队友，奶骑怒而afk。第一赛季3v3定格在了2199。 转 5.2开启，寝室一众人转去了19组安苏LM，恰逢鹦鹉贼+8800sp无比强势，捡起了TBC的骑士号，贼骑朝着2200飞奔而去，无奈法牧版本。贼骑最终止步2000。在此期间认识了面向大海（通信学院学弟），阿七（一个除了吹比啥都不会的ss），十月（军需官面前认识的万年cjq），买糖（国服最强的竞争者萨满），最终都成为了日后的队友。同时，看了hydra的视频，恰逢ms强势版本，转行玩ms，和阿黄开始了法牧生涯。 5.3鹦鹉贼削弱，22贼牧再次起飞，止步2150，和兰服猎人无涯和兔子惩猎牧经过2小时的厮杀冲破2200，接近2400，随后兔子afk，借了个小号打起了毫无希望的贼猎牧，没想到一路横冲直撞冲上了2400，怒把自己的号退队一起打贼猎牧，队友全都获得了2400成就，然而我的分数最终定格2398，再也没有上分。55同时开打，贼法猎惩牧（麻子，阿黄，无涯，十月），4dd在21组横行，最高55 21组第二。22在此期间也成功通过法牧上了2200，获得竞技场大师成就，获得决斗者。 LM 33贼法牧也逐渐成型，在暴虐结算当天的前一天开打，两个晚上接近70%胜率接近2400。打的同工会的3板悲伤的下线，死磕战法牧，最终因为网络原因定格2397。也算是一个遗憾吧，两个号都没有获得2400成就。 5.4 一开始法术骑和贼法牧就同时获得了3v3 2700成就。55法三远（阿黄，阿七，天才高中生 张良，鸽王 味陌）也是一路高胜率2700。22 也在那个赛季打到了2700+，算是挺圆满的，就差一个斗士了。 5.x版本是个充斥着刷分的版本，认识了很多新朋友，因为刷子很多人再也没有回到wow。合 6.0开服之后顺利的拿到了斗士，也算是一种圆满吧。贼法德玩的很开心，惩戒骑也上过评级第一页，虽然没拿到英雄，但是好像已经不在意那些事情了，面临毕业，还有很多重要的事情需要去完成，慢慢地淡出了wow，感谢在艾泽拉斯的那段岁月。 感谢很多没有提到的朋友，nga美少女–艾琳.冰冻丢墙上.纳斯，评级牧神–Slience，逗比奶僧–咸鱼，我吃个饭就回来–萌萌的喵喵.微娘。还有竹爷，羊哥，Smudgelol，Sinsin，EE，耗子，杀生 等等。 最后，鲜血与荣耀，为了部落！Lok-tar ogar! 电子设备换了一波又一波，没有图了。最后上个图吧~]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>wow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tree Traversal]]></title>
    <url>%2F2017%2F03%2F27%2FTree-Traversal%2F</url>
    <content type="text"><![CDATA[pre order Pre-order: F, B, A, D, C, E, G, I, H. Check if the current node is empty / null Display the data part of the root (or current node). Traverse the left subtree by recursively calling the pre-order function. Traverse the right subtree by recursively calling the pre-order function. 1234567891011121314public class Solution &#123; public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; Stack&lt;TreeNode&gt; s = new Stack&lt;TreeNode&gt;(); List&lt;Integer&gt; res = new LinkedList&lt;Integer&gt;(); if(root!=null) s.push(root); while(!s.isEmpty())&#123; TreeNode curr = s.pop(); res.add(curr.val); if(curr.right!=null) s.push(curr.right); if(curr.left!=null) s.push(curr.left); &#125; return res; &#125;&#125; in order In-order: A, B, C, D, E, F, G, H, I. Check if the current node is empty / null Traverse the left subtree by recursively calling the in-order function. Display the data part of the root (or current node). Traverse the right subtree by recursively calling the in-order function. In a search tree, in-order traversal retrieves data in sorted order. 123456789101112131415161718192021222324252627public class Solution &#123; public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new LinkedList&lt;Integer&gt;(); Stack&lt;TreeNode&gt; s = new Stack&lt;TreeNode&gt;(); //先将最左边的节点都push进栈 if(root!=null)&#123; pushAllTheLeft(s, root); &#125; while(!s.isEmpty())&#123; TreeNode curr = s.pop(); res.add(curr.val); //如果有右子树，将右节点和右子树的最左边的节点都push进栈 if(curr.right != null)&#123; pushAllTheLeft(s, curr.right); &#125; &#125; return res; &#125; private void pushAllTheLeft(Stack&lt;TreeNode&gt; s, TreeNode root)&#123; s.push(root); while(root.left!=null)&#123; root = root.left; s.push(root); &#125; &#125;&#125; post order Post-order: A, C, E, D, B, H, I, G, F. Check if the current node is empty / null Traverse the left subtree by recursively calling the post-order function. Traverse the right subtree by recursively calling the post-order function. Display the data part of the root (or current node). The trace of a traversal is called a sequentialisation of the tree. The traversal trace is a list of each visited root. No one sequentialisation according to pre-, in- or post-order describes the underlying tree uniquely. Given a tree with distinct elements, either pre-order or post-order paired with in-order is sufficient to describe the tree uniquely. However, pre-order with post-order leaves some ambiguity in the tree structure. 123456789101112131415161718192021222324252627282930 public class Solution &#123; public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123; Stack&lt;PowerNode&gt; s = new Stack&lt;PowerNode&gt;(); List&lt;Integer&gt; res = new LinkedList&lt;Integer&gt;(); if(root!=null) s.push(new PowerNode(root, false)); while(!s.isEmpty())&#123; PowerNode curr = s.peek(); //如果是第二次访问，就计算并pop该节点 if(curr.visited)&#123; res.add(curr.node.val); s.pop(); &#125; else &#123; //如果是第一次访问，就将它的左右节点加入stack，并设置其已经访问了一次 if(curr.node.right!=null) s.push(new PowerNode(curr.node.right, false)); if(curr.node.left!=null) s.push(new PowerNode(curr.node.left, false)); curr.visited = true; &#125; &#125; return res; &#125; private class PowerNode &#123; TreeNode node; boolean visited; public PowerNode(TreeNode n, boolean v)&#123; this.node = n; this.visited = v; &#125; &#125;&#125; 参见wiki 参见[leetcode] Binary Tree Traversal 二叉树遍历]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>data-structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[垃圾回收]]></title>
    <url>%2F2017%2F03%2F11%2F%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[判定对象是否存活引用计数法 优点 简单，容易实现 缺点 无法解决循环引用的问题，代码如下 当r1 r2 的实例仅仅是互相引用的时候，如果有引用计数器他们不会被回收，而看gc日志，很明显会被回收。存在的问题源码123456789101112131415161718192021public class ReferencingCountingGC &#123; public static int _1M = 1024 * 1024; public Object instance = null; private byte[] value = new byte[2 * _1M]; public static void main(String[] args) &#123; ReferencingCountingGC r1 = new ReferencingCountingGC(); ReferencingCountingGC r2 = new ReferencingCountingGC(); r1.instance = r2; r2.instance = r1; r1 = null; r2 = null; System.gc(); &#125;&#125; [GC (System.gc()) [PSYoungGen: 11055K-&gt;1351K(38400K)] 11055K-&gt;1359K(125952K), 0.0025286 secs] [Times: user=0.01 sys=0.01, real=0.00 secs][Full GC (System.gc()) [PSYoungGen: 1351K-&gt;0K(38400K)] [ParOldGen: 8K-&gt;1241K(87552K)] 1359K-&gt;1241K(125952K), [Metaspace: 3370K-&gt;3370K(1056768K)], 0.0081339 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 可达性分析算法原理 当一个对象到GC ROOTS 没有任何引用链相连时，则证明此对象不可用。 即上文讲的r1 r2 互相关联，但是他们并没有被GC ROOTS关联，所以他们会被回收。GC ROOTS的对象 虚拟机栈中引用的对象。 方法区中类静态属性引用的对象 方法去中常量引用的对象。 本地方法栈中JNI（即一般说的native方法）引用的对象。问题上文的r1 r2 本身也是虚拟机栈中的引用，本身可以成为gc roots，那么对象为什么还会被回收呢。回答所谓“GC roots”，或者说tracing GC的“根集合”，就是一组必须活跃的引用。例如说，这些引用可能包括： 所有Java线程当前活跃的栈帧里指向GC堆里的对象的引用；换句话说，当前所有正在被调用的方法的引用类型的参数/局部变量/临时值。 VM的一些静态数据结构里指向GC堆里的对象的引用，例如说HotSpot VM里的Universe里有很多这样的引用。 JNI handles，包括global handles和local handles （看情况）所有当前被加载的Java类 （看情况）Java类的引用类型静态变量 （看情况）Java类的运行时常量池里的引用类型常量（String或Class类型） （看情况）String常量池（StringTable）里的引用注意，是一组必须活跃的引用，不是对象。 活跃很重要，r1 r2 是非活跃的所以没有被划分为gc rootsgc roots 详细解释 关于引用 强引用：只要强引用还存在就不会被回收 软引用（SoftReference）：在内存即将溢出之时，对这些对象做二次回收，如果还没有足够内存才会内存溢出异常。 弱引用（WeakReference）: 之前做jdk动态代理，weak cache的时候有接触，下一次gc之前被回收 虚引用（PhantomReference）: 一个对象是否有虚引用的存在，不会对生存周期构成影响，也无法通过虚引用来取得一个对象实例。对一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。 关于finalize 不可达的对象，要经历两次标记过程。 实现finalize方法且没有被调用的对象，会被放置在一个F-Queue的队列（由虚拟机自动建立，低优先级的Finalizer线程去执行）之中，但是不保证会执行完成（可能会含有死循环等异常。） 不推荐使用finalize方法 回收方法区 废弃常量 与堆类似 废弃类 所有实例已被回收。 classloader已被回收。 对应的Class没有任何地方被引用，无法再任何地方通过反射访问该类。（用spring这条基本都是不符合了吧。。。） 满足上述条件，仅仅是可回收。 垃圾回收算法 标记-清除算法（统一标记，统一删除） 效率不高。（GC ROOTS标记的是存活对象，查找死亡对象还需一次遍历？） 容易产生内存碎片。 复制算法（将内存分为两部分，每次只使用其中的一块，gc时将存活的对象复制到另外一块上去，清空原来的内存空间）。 每次只能使用一半的内存 虚拟机通过这个算法来回收新生代，分为eden : survivor1 : survivor2 = 8:1:1 （98%的对象在回收时都会被回收，每次将 eden + survivor 复制到 另一个survivor，如果超过了10%则需要老年代来做担保）。 标记-整理算法（存活的对象都向一端移动，避免碎片） 不需要额外的空间 分代收集算法 新生代 存活率低 适合复制算法 老年代 存活率高 适合标记-整理 或者 标记-清理算法。 安全点 &amp; 安全区域 不能再所有地方 程序运行到safe point才能进行gc 为防止blocking等长时间没有分配cpu的情况 在HotSpot中，对象的类型信息里有记录自己的OopMap，记录了在该类型的对象内什么偏移量上是什么类型的数据。所以从对象开始向外的扫描可以是准确的；这些数据是在类加载过程中计算得到的。 可以把oopMap简单理解成是调试信息。 在源代码里面每个变量都是有类型的，但是编译之后的代码就只有变量在栈上的位置了。oopMap就是一个附加的信息，告诉你栈上哪个位置本来是个什么东西。 这个信息是在JIT编译时跟机器码一起产生的。因为只有编译器知道源代码跟产生的代码的对应关系。 每个方法可能会有好几个oopMap，就是根据safepoint把一个方法的代码分成几段，每一段代码一个oopMap，作用域自然也仅限于这一段代码。 循环中引用多个对象，肯定会有多个变量，编译后占据栈上的多个位置。那这段代码的oopMap就会包含多条记录。 对Java线程中的JNI方法，它们既不是由JVM里的解释器执行的，也不是由JVM的JIT编译器生成的，所以会缺少OopMap信息。那么GC碰到这样的栈帧该如何维持准确性呢？HotSpot的解决方法是：所有经过JNI调用边界（调用JNI方法传入的参数、从JNI方法传回的返回值）的引用都必须用“句柄”（handle）包装起来。JNI需要调用Java API的时候也必须自己用句柄包装指针。在这种实现中，JNI方法里写的“jobject”实际上不是直接指向对象的指针，而是先指向一个句柄，通过句柄才能间接访问到对象。这样在扫描到JNI方法的时候就不需要扫描它的栈帧了——只要扫描句柄表就可以得到所有从JNI方法能访问到的GC堆里的对象。但这也就意味着调用JNI方法会有句柄的包装/拆包装的开销，是导致JNI方法的调用比较慢的原因之一。 垃圾收集器serial收集器 采用复制算法 仅使用一个线程或者一个cpu区完成垃圾收集工作。 垃圾收集时会暂停其他所有的工作线程。 适用于client端（应该说是单CPU情况下），简单高效 ParNew收集器 采用复制算法 多线程的Serial收集器 除Serial之外仅有的能与CMS收集器配合工作的收集器 随着cpu的增加性能会好于Serial收集器（垃圾收集可看做是计算密集型，线程切换会有开销） Parallel Scavenge 采用复制算法 多线程收集 目的：达到可控制的吞吐量（吞吐量=用户运行时间/(用户运行时间+垃圾收集时间)），简而言之就是减少停顿 参数可调：GCTimeRatio &amp; MAXGCPauseMillis ，可自适应（GC停顿时间是牺牲吞吐量和新生代空间换来的，新生代越小收集的越快，但是系统损耗的占比越高，其实收集效率越低） SerialOld 收集器 Serial老年版 与 Parallel Scavenge 可以一起使用 Parallel Old收集器 Parallel Scavenge 老年版 标记整理算法 在注重吞吐量和CPU资源敏感的场合可以考虑使用。 CMS 目标-减少停顿时间 初始标记（仅遍历GC ROOTS，速度快） 并发标记（GC ROOTS TRACING，速度慢） 重新标记（修正并发标记产生变更的部分） 并发清楚（清除数据，速度慢） 并发标记和并发清楚可以与用户线程一起执行，停顿就会减少 缺点： CMS在并发标记和并发清楚的时候会占用cpu 并发清理阶段产生的新垃圾无法及时清楚，可能会引起再一次的full gc(因为应用线程同时执行，所以要预留空间，cms触发要比其他收集器早) 基于标记-清理的内存碎片的问题。 G1 TODO 其他 对象优先在Eden分配 大对象直接进入老年代 长期存活的对象进入老年代（版本号，默认15） survivor空间中相同版本的所有对象大小总和大于Survivor控件的一半时，直接进入老年代]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
</search>